import json
import math
import threading
import time

import cv2
import mediapipe as mp
import numpy as np
import websocket

# Mediapipe ì´ˆê¸°í™”
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils


# ë©€í‹°ìŠ¤ë ˆë”© ì¹´ë©”ë¼ ë¦¬ë” í´ë˜ìŠ¤
class ThreadedCamera:
    """ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì¹´ë©”ë¼ í”„ë ˆì„ì„ ì½ì–´ ì„±ëŠ¥ í–¥ìƒ"""

    def __init__(self, src=0):
        self.capture = cv2.VideoCapture(src)
        self.capture.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ë²„í¼ ìµœì†Œí™”
        self.thread = threading.Thread(target=self.update, args=())
        self.thread.daemon = True
        self.frame = None
        self.ret = False
        self.running = False

    def start(self):
        self.running = True
        self.thread.start()
        return self

    def update(self):
        while self.running:
            if self.capture.isOpened():
                self.ret, self.frame = self.capture.read()

    def read(self):
        return self.ret, self.frame

    def stop(self):
        self.running = False
        self.thread.join()

    def release(self):
        self.stop()
        self.capture.release()


# ì „ì—­ ë³€ìˆ˜ë“¤
MODE_CONFIRMATION_THRESHOLD = 3
MODE5_CONFIRM_FRAMES = 100
ANGLE_THRESHOLD = 150

# ê²€ì§€-ì¤‘ì§€ ê±°ë¦¬ ì„ê³„ê°’ (ì •ê·œí™”ëœ ê±°ë¦¬ ê¸°ì¤€)
INDEX_MIDDLE_DISTANCE_THRESHOLD = 120.0

# ì œìŠ¤ì²˜ ì•ˆì •í™”ë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ë“¤
GESTURE_STABILIZATION_TIME = 0.3  # 0.5ì´ˆ
current_gesture_candidate = None
gesture_start_time = None
stable_gesture = None

# Unity ì›¹ì†Œì¼“ í†µì‹  ì„¤ì •
UNITY_WEBSOCKET_URL = "ws://localhost:8765/gesture"
unity_websocket = None
last_sent_gesture = None

# ì œìŠ¤ì²˜ ìˆ«ì ë§¤í•‘
GESTURE_TO_NUMBER = {
    "L": 1,
    "3": 2,
    "B": 3,
    "G": 4,
    "1": 5,
    "L-I": 6,
    "1-I": 7,
    "8": 8,
    "Open N": 9,
    "Bent 3": 10,
    "Baby O": 11,
    # ë¬´ê¸° ì œìŠ¤ì²˜
    "3_Fire": 4,  # ì†Œì´ ë°œì‚¬ -> G ë²ˆí˜¸ ì‚¬ìš©
    "3_Reload": 5,  # ì†Œì´ ì¬ì¥ì „ -> 1 ë²ˆí˜¸ ì‚¬ìš©
    "SG": 4,  # ìƒ·ê±´ ë°œì‚¬ [0,1,1,1,1] -> G ë²ˆí˜¸ ì‚¬ìš©
    "S1": 5,  # ìƒ·ê±´ ì¬ì¥ì „ [-1,1,1,1,1] -> 1 ë²ˆí˜¸ ì‚¬ìš©
    "M1": 5,  # ì†Œì´ ì¬ì¥ì „2 [-1,1,1,-1,-1] -> 1 ë²ˆí˜¸ ì‚¬ìš©
}

# ì—„ì§€-ë‹¤ë¥¸ì†ê°€ë½ ì ‘ì´‰ ì„ê³„ê°’ (í”½ì…€ ê±°ë¦¬ ê¸°ì¤€)
THUMB_TOUCH_THRESHOLD = 24

# ì—„ì§€ì™€ Ring DIP ê·¼ì ‘ íŒì •ìš© ì„ê³„ê°’ (ì •ê·œí™”ëœ palm_width ê¸°ì¤€)
RING_DIP_THUMB_THRESHOLD = 0.06


# ê° ì¹´ë©”ë¼ë³„ ìƒíƒœë¥¼ ì €ì¥í•  í´ë˜ìŠ¤
class CameraState:
    def __init__(self, camera_id, camera_type="top"):
        self.camera_id = camera_id
        self.camera_type = camera_type  # "top" ë˜ëŠ” "bottom"
        self.mode_confirmation_count = 0
        self.last_detected_mode = None
        self.last_confirmed_mode = None
        self.last_sent_mode = None
        self.last_sent_is = None
        self.mode5_counter = 0
        self.prev_mode = None
        self.mode = None

        # ì†ê°€ë½ ê°ë„ ì €ì¥ (ë‹¤ë¥¸ ì¹´ë©”ë¼ì™€ ê³µìœ ìš©)
        self.finger_angles = {}

        # ì†ê°€ë½ ìƒíƒœ ì €ì¥ (1: straight, 0: between, -1: bent)
        self.finger_states_numeric = {}

        # ìŠ¤ë¬´ë”© ê°ì²´ë“¤
        self.distance_smoother = ExponentialMovingAverage(alpha=0.2)
        self.angle_smoother = ExponentialMovingAverage(alpha=0.1)
        self.thumb_angle_smoother = ExponentialMovingAverage(alpha=0.1)

        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œìŠ¤í…œ
        self.calibration = CalibrationSystem()

        # ì›¹ì†Œì¼“ ì „ì†¡ íƒ€ì´ë°
        self.last_send_time = time.time()

        # ì†ë‚ (ì¸¡ë©´) ë°©í–¥ ê°ì§€
        self.is_side_facing = False
        self.palm_normal_z = 0.0
        self.side_facing_confidence = 0.0


# ì§€ìˆ˜ì´ë™í‰ê·  ìŠ¤ë¬´ë”© í´ë˜ìŠ¤
class ExponentialMovingAverage:
    def __init__(self, alpha=0.1):
        self.alpha = alpha
        self.last_value = None

    def smooth(self, value):
        if self.last_value is None:
            self.last_value = value
            return value
        smoothed_value = self.alpha * value + (1 - self.alpha) * self.last_value
        self.last_value = smoothed_value
        return smoothed_value

    def reset(self):
        self.last_value = None


# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œìŠ¤í…œ
class CalibrationSystem:
    def __init__(self):
        self.state = "ready"
        self.mode1_values = []
        self.mode2_values = []
        self.mode1_min = None
        self.mode1_max = None
        self.mode2_min = None
        self.mode2_max = None
        self.collection_count = 0
        self.target_samples = 60

        self.mode1_range_10_90 = None
        self.mode1_offset_10 = None
        self.mode2_range_10_90 = None
        self.mode2_offset_10 = None

    def get_remaining_time(self):
        remaining_frames = self.target_samples - self.collection_count
        remaining_seconds = remaining_frames / 30.0
        return max(0, remaining_seconds)

    def start_mode1_calibration(self):
        self.state = "mode1_collect"
        self.mode1_values = []
        self.collection_count = 0

    def start_mode2_calibration(self):
        self.state = "mode2_collect"
        self.mode2_values = []
        self.collection_count = 0

    def collect_sample(self, mode, distance_value):
        if self.state == "mode1_collect" and mode == "mode1":
            self.mode1_values.append(distance_value)
            self.collection_count += 1
            if self.collection_count >= self.target_samples:
                self.mode1_min = min(self.mode1_values)
                self.mode1_max = max(self.mode1_values)
                self._update_mode1_cache()
                self.state = "ready"

        elif self.state == "mode2_collect" and mode == "mode2":
            self.mode2_values.append(distance_value)
            self.collection_count += 1
            if self.collection_count >= self.target_samples:
                self.mode2_min = min(self.mode2_values)
                self.mode2_max = max(self.mode2_values)
                self._update_mode2_cache()
                self.state = "ready"

    def _update_mode1_cache(self):
        if self.mode1_min is not None and self.mode1_max is not None:
            range_val = self.mode1_max - self.mode1_min
            if range_val > 1e-6:
                self.mode1_range_10_90 = range_val * 0.7
                self.mode1_offset_10 = self.mode1_min + range_val * 0.15
            else:
                self.mode1_range_10_90 = None
                self.mode1_offset_10 = None

    def _update_mode2_cache(self):
        if self.mode2_min is not None and self.mode2_max is not None:
            range_val = self.mode2_max - self.mode2_min
            if range_val > 1e-6:
                self.mode2_range_10_90 = range_val * 0.7
                self.mode2_offset_10 = self.mode2_min + range_val * 0.15
            else:
                self.mode2_range_10_90 = None
                self.mode2_offset_10 = None

    def is_calibrated(self):
        return (
            self.mode1_min is not None
            and self.mode1_max is not None
            and self.mode2_min is not None
            and self.mode2_max is not None
        )

    def get_percentage(self, mode, distance_value):
        if (
            mode == "mode1"
            and self.mode1_range_10_90 is not None
            and self.mode1_offset_10 is not None
        ):
            normalized = (
                distance_value - self.mode1_offset_10
            ) / self.mode1_range_10_90
            return max(0, min(120, normalized * 100))
        elif (
            mode == "mode2"
            and self.mode2_range_10_90 is not None
            and self.mode2_offset_10 is not None
        ):
            normalized = (
                distance_value - self.mode2_offset_10
            ) / self.mode2_range_10_90
            return max(0, min(120, normalized * 100))
        return None

    def set_defaults(self):
        self.mode1_min = 0.3
        self.mode1_max = 1.5
        self.mode2_min = 0.1
        self.mode2_max = 0.8
        self._update_mode1_cache()
        self._update_mode2_cache()
        self.state = "ready"

    def reset(self):
        self.state = "ready"
        self.mode1_values = []
        self.mode2_values = []
        self.mode1_min = None
        self.mode1_max = None
        self.mode2_min = None
        self.mode2_max = None
        self.collection_count = 0
        self.mode1_range_10_90 = None
        self.mode1_offset_10 = None
        self.mode2_range_10_90 = None
        self.mode2_offset_10 = None


def check_hand_orientation(hand_landmarks):
    """ì†ëª©ì˜ ë°©í–¥ì„ í™•ì¸í•˜ì—¬ íŒ”ì´ ìˆ˜ì§ì¸ì§€ íŒë‹¨"""
    wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]
    middle_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_MCP]
    hand_vector_y = middle_mcp.y - wrist.y
    is_arm_raised = hand_vector_y < -0.05
    return is_arm_raised


def check_hand_side_orientation(hand_landmarks, camera_type="side"):
    """
    ì†ì´ ì¸¡ë©´(ì†ë‚ )ì„ í–¥í•˜ëŠ”ì§€ íŒë‹¨í•©ë‹ˆë‹¤.
    ì†ë°”ë‹¥ì˜ ë²•ì„  ë²¡í„°ë¥¼ ê³„ì‚°í•˜ì—¬ Zì¶• ë°©í–¥ ì„±ë¶„ì„ í™•ì¸í•©ë‹ˆë‹¤.

    Args:
        hand_landmarks: MediaPipe ì† ëœë“œë§ˆí¬
        camera_type: "side" ë˜ëŠ” "bottom" - ì¹´ë©”ë¼ë³„ë¡œ ë‹¤ë¥¸ ì„ê³„ê°’ ì ìš©

    Returns:
        tuple: (is_side_facing: bool, palm_normal_z: float, confidence: float)
            - is_side_facing: ì†ì´ ì¸¡ë©´ì„ í–¥í•˜ë©´ True
            - palm_normal_z: ì†ë°”ë‹¥ ë²•ì„ ì˜ Z ì„±ë¶„
            - confidence: íŒì • ì‹ ë¢°ë„ (0.0 ~ 1.0)
    """
    try:
        # ì†ë°”ë‹¥ í‰ë©´ì„ ì •ì˜í•˜ëŠ” 3ê°œì˜ ì 
        wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]
        index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]
        pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]

        # ë‘ ë²¡í„° ê³„ì‚°
        # v1: wrist -> index_mcp
        v1 = (index_mcp.x - wrist.x, index_mcp.y - wrist.y, index_mcp.z - wrist.z)

        # v2: wrist -> pinky_mcp
        v2 = (pinky_mcp.x - wrist.x, pinky_mcp.y - wrist.y, pinky_mcp.z - wrist.z)

        # ì™¸ì (cross product)ìœ¼ë¡œ ì†ë°”ë‹¥ í‰ë©´ì˜ ë²•ì„  ë²¡í„° ê³„ì‚°
        # normal = v1 Ã— v2
        normal_x = v1[1] * v2[2] - v1[2] * v2[1]
        normal_y = v1[2] * v2[0] - v1[0] * v2[2]
        normal_z = v1[0] * v2[1] - v1[1] * v2[0]

        # ë²•ì„  ë²¡í„° ì •ê·œí™”
        magnitude = math.sqrt(normal_x**2 + normal_y**2 + normal_z**2)

        if magnitude < 1e-6:
            return False, 0.0, 0.0

        norm_x = normal_x / magnitude
        norm_y = normal_y / magnitude
        norm_z = normal_z / magnitude

        # ì¹´ë©”ë¼ë³„ ì„ê³„ê°’ ì„¤ì •
        # ì¸¡ë©´(ìƒë‹¨) ì¹´ë©”ë¼: norm_z <= threshold ì´ë©´ ì†ë‚  (ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ -0.1ë¡œ ì¡°ì •)
        # í•˜ë‹¨ ì¹´ë©”ë¼: norm_z >= -0.5 ì´ë©´ ì†ë‚  (í•˜ë‹¨ì€ ë°˜ëŒ€ë¡œ ì ìš©)

        if camera_type == "side":
            # ì¸¡ë©´ ì¹´ë©”ë¼: norm_z <= 0.3 ì´ë©´ ì†ë‚  (ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ìƒë‹¨ ê¸°ì¤€ ì„ê³„ê°’ì„ 0.3ìœ¼ë¡œ ì„¤ì •)
            threshold = 0.3
            is_side = norm_z <= threshold

            # ì‹ ë¢°ë„ ê³„ì‚°: thresholdë³´ë‹¤ ì‘ì•„ì§ˆìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€
            if norm_z <= threshold:
                confidence = min(1.0, max(0.0, (threshold - norm_z) / 0.7))
            else:
                confidence = 0.0
        else:
            # í•˜ë‹¨ ì¹´ë©”ë¼: norm_z >= -0.5 ì´ë©´ ì†ë‚  (ë°˜ëŒ€ë¡œ ì ìš©)
            threshold = -0.5
            is_side = norm_z >= threshold

            # ì‹ ë¢°ë„ ê³„ì‚°: thresholdë³´ë‹¤ í´ìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€
            if norm_z >= threshold:
                confidence = min(1.0, max(0.0, (norm_z - threshold) / 0.7))
            else:
                confidence = 0.0

        return is_side, norm_z, confidence

    except Exception:
        return False, 0.0, 0.0


def is_thumb_extended(hand_landmarks, handedness):
    mcp = hand_landmarks.landmark[2]
    tip = hand_landmarks.landmark[4]
    index_mcp = hand_landmarks.landmark[5]
    middle_mcp = hand_landmarks.landmark[9]
    ring_mcp = hand_landmarks.landmark[13]
    pinky_mcp = hand_landmarks.landmark[17]

    palm_cx = (index_mcp.x + middle_mcp.x + ring_mcp.x + pinky_mcp.x) / 4
    palm_cy = (index_mcp.y + middle_mcp.y + ring_mcp.y + pinky_mcp.y) / 4

    dist_tip_palm = math.hypot(tip.x - palm_cx, tip.y - palm_cy)
    dist_mcp_tip = math.hypot(tip.x - mcp.x, tip.y - mcp.y)

    angle = calculate_angle(
        (mcp.x, mcp.y),
        (hand_landmarks.landmark[3].x, hand_landmarks.landmark[3].y),
        (tip.x, tip.y),
    )

    if dist_tip_palm < dist_mcp_tip * 0.8:
        return False

    index_pip = hand_landmarks.landmark[6]
    thumb_index_distance = math.hypot(tip.x - index_pip.x, tip.y - index_pip.y)
    palm_width = math.hypot(index_mcp.x - pinky_mcp.x, index_mcp.y - pinky_mcp.y)

    if thumb_index_distance < palm_width * 0.8:
        return False

    if angle > 145 and angle < 180:
        if handedness == "Right":
            return tip.x > mcp.x and tip.x > hand_landmarks.landmark[1].x
        else:
            return tip.x < mcp.x and tip.x < hand_landmarks.landmark[1].x
    return False


def calculate_angle(a, b, c):
    """a, b, cëŠ” (x, y) íŠœí”Œ. bëŠ” ê°ë„ì˜ ê¼­ì§“ì """
    ba = (a[0] - b[0], a[1] - b[1])
    bc = (c[0] - b[0], c[1] - b[1])
    cosine_angle = (ba[0] * bc[0] + ba[1] * bc[1]) / (
        math.sqrt(ba[0] ** 2 + ba[1] ** 2) * math.sqrt(bc[0] ** 2 + bc[1] ** 2) + 1e-6
    )
    angle = math.acos(cosine_angle)
    return math.degrees(angle)


def calculate_angle_3d(a, b, c):
    """a, b, cëŠ” (x, y, z) íŠœí”Œ. bëŠ” ê°ë„ì˜ ê¼­ì§“ì  - 3D ë²¡í„° ê³„ì‚°"""
    ba = (a[0] - b[0], a[1] - b[1], a[2] - b[2])
    bc = (c[0] - b[0], c[1] - b[1], c[2] - b[2])

    dot_product = ba[0] * bc[0] + ba[1] * bc[1] + ba[2] * bc[2]
    magnitude_ba = math.sqrt(ba[0] ** 2 + ba[1] ** 2 + ba[2] ** 2)
    magnitude_bc = math.sqrt(bc[0] ** 2 + bc[1] ** 2 + bc[2] ** 2)

    cosine_angle = dot_product / (magnitude_ba * magnitude_bc + 1e-6)
    cosine_angle = max(-1.0, min(1.0, cosine_angle))

    angle = math.acos(cosine_angle)
    return math.degrees(angle)


def calculate_thumb_spread_angle(hand_landmarks, handedness):
    """ì—„ì§€ ê´€ì ˆ ê°ë„ ê³„ì‚°"""
    mcp = hand_landmarks.landmark[2]
    ip = hand_landmarks.landmark[3]
    tip = hand_landmarks.landmark[4]

    joint_angle = calculate_angle_3d(
        (mcp.x, mcp.y, mcp.z), (ip.x, ip.y, ip.z), (tip.x, tip.y, tip.z)
    )

    index_mcp = hand_landmarks.landmark[5]
    thumb_index_distance = math.sqrt(
        (tip.x - index_mcp.x) ** 2
        + (tip.y - index_mcp.y) ** 2
        + (tip.z - index_mcp.z) ** 2
    )

    wrist = hand_landmarks.landmark[0]
    hand_size = math.sqrt(
        (index_mcp.x - wrist.x) ** 2
        + (index_mcp.y - wrist.y) ** 2
        + (index_mcp.z - wrist.z) ** 2
    )

    normalized_spread = thumb_index_distance / (hand_size + 1e-6)

    if normalized_spread > 1.2:
        return +joint_angle
    elif normalized_spread < 0.8:
        return -(joint_angle * 1.5)
    else:
        return +(joint_angle * 0.7)


def finger_angle(hand_landmarks, mcp_id, pip_id, tip_id):
    mcp = hand_landmarks.landmark[mcp_id]
    pip = hand_landmarks.landmark[pip_id]
    tip = hand_landmarks.landmark[tip_id]
    return calculate_angle((mcp.x, mcp.y), (pip.x, pip.y), (tip.x, tip.y))


def classify_thumb_state_side(hand_landmarks, camera_type="side", handedness="Right"):
    """
    ì¸¡ë©´/í•˜ë‹¨ ì¹´ë©”ë¼ì—ì„œ ì—„ì§€ ìƒíƒœ ë¶„ë¥˜: 1(straight) / 0(between) / -1(bent)

    Args:
        hand_landmarks: MediaPipe ì† ëœë“œë§ˆí¬
        camera_type: "side" ë˜ëŠ” "bottom"

    Returns:
        1: straight (í´ì§), 0: between (ì¤‘ê°„), -1: bent (êµ½í˜)
    """
    # ì—„ì§€ ëœë“œë§ˆí¬
    thumb_tip = hand_landmarks.landmark[4]  # ë

    # ê²€ì§€ MCP (ë¹„êµ ê¸°ì¤€)
    index_mcp = hand_landmarks.landmark[5]

    if camera_type == "side":
        # ì¸¡ë©´ ì¹´ë©”ë¼: Xì¶• ê±°ë¦¬ë¡œ íŒë‹¨ (ì—„ì§€ê°€ í´ì§€ë©´ Xê°€ ì»¤ì§)
        # ì¸¡ë©´ ì¹´ë©”ë¼: ê°„ë‹¨íˆ í´ì§ìœ¼ë¡œ ê°„ì£¼
        return 1, None  # straight (ë¬´ì¡°ê±´ í´ì§), normalized_yëŠ” None
    else:
        # í•˜ë‹¨ ì¹´ë©”ë¼: tracking.pyì™€ ë™ì¼í•œ normalized ì¢Œí‘œ ê¸°ë°˜ zone íŒì • + In1/In2/In3 ì„¸ë¶„í™”

        # ì† í¬ê¸° ê¸°ì¤€ ê³„ì‚°
        wrist = hand_landmarks.landmark[0]
        middle_mcp = hand_landmarks.landmark[9]
        pinky_mcp = hand_landmarks.landmark[17]

        hand_length = math.hypot(middle_mcp.x - wrist.x, middle_mcp.y - wrist.y)
        palm_width = math.hypot(index_mcp.x - pinky_mcp.x, index_mcp.y - pinky_mcp.y)

        # ì†ë°”ë‹¥ ì¤‘ì‹¬ ê³„ì‚°
        palm_center_x = (wrist.x + index_mcp.x + pinky_mcp.x) / 3
        palm_center_y = (wrist.y + index_mcp.y + pinky_mcp.y) / 3

        # ì—„ì§€ ëì—ì„œ ì†ë°”ë‹¥ ì¤‘ì‹¬ê¹Œì§€ì˜ ë²¡í„° (ì •ê·œí™”)
        thumb_vector_x = (thumb_tip.x - palm_center_x) / (palm_width + 1e-6)
        thumb_vector_y = (thumb_tip.y - palm_center_y) / (hand_length + 1e-6)

        # ì™¼ì†/ì˜¤ë¥¸ì†ì— ë”°ë¥¸ ì¡°ì •
        if handedness == "Left":
            thumb_vector_x = -thumb_vector_x

        normalized_x = thumb_vector_x
        normalized_y = thumb_vector_y

        # Zone íŒì • ì„ê³„ê°’ (tracking.pyì™€ ë™ì¼)
        THUMB_INNER_THRESHOLD = 0.54
        THUMB_OUTER_THRESHOLD = 1.4
        INNER_Y_HIGH_THRESHOLD = 0.55  # >= 0.55: In3
        INNER_Y_LOW_THRESHOLD = 0.27  # < 0.27: In1, 0.27~0.55: In2

        # Zone íŒë³„
        thumb_zone = "center"

        if normalized_x <= THUMB_INNER_THRESHOLD:
            thumb_zone = "inner"
            # Inner State ì„¸ë¶„í™” (Yê°’ ê¸°ì¤€)
            # (ì„œë¸Œì¡´ ì •ë³´ëŠ” ì—¬ê¸°ì„œëŠ” íŒì •ì— ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
            if normalized_y >= INNER_Y_HIGH_THRESHOLD:
                pass
            elif normalized_y >= INNER_Y_LOW_THRESHOLD:
                pass
            else:
                pass
        elif normalized_x >= THUMB_OUTER_THRESHOLD:
            thumb_zone = "outer"

        # Zoneë³„ straight/bent íŒì • (In1/In2/In3 ì„¸ë¶„í™” ì ìš©)
        if thumb_zone == "outer":
            return 1, normalized_y  # straight
        elif thumb_zone == "inner":
            return -1, normalized_y  # bent
        else:
            return 0, normalized_y  # between


def classify_finger_state_single_angle(
    angle_side,
    angle_bottom=None,
    y_pos_side=None,
    y_pos_bottom=None,
    is_side_facing=False,
    finger_name=None,
):
    """
    ì‹±ê¸€ ê°ë„ ì†ê°€ë½ ìƒíƒœ ë¶„ë¥˜: 1(straight) / 0(between) / -1(bent)

    í•µì‹¬ ë¡œì§:
    1. ì¸¡ë©´ ì¹´ë©”ë¼ ê°ë„ë¡œ 1ì°¨ íŒì • (MCP-PIP-TIPë§Œ ì‚¬ìš©)
    2. í•˜ë‹¨ ì¹´ë©”ë¼ ìˆìœ¼ë©´ ë‘ ì¹´ë©”ë¼ ìœµí•©
    3. Lower ê°ë„ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì‹±ê¸€ ê°ë„ë§Œ)

    Args:
        angle_side: ì¸¡ë©´ ì¹´ë©”ë¼ ì†ê°€ë½ ê°ë„ (MCP-PIP-TIP)
        angle_bottom: í•˜ë‹¨ ì¹´ë©”ë¼ ì†ê°€ë½ ê°ë„ (optional)
        y_pos_side: ì¸¡ë©´ ì¹´ë©”ë¼ì—ì„œ ì†ê°€ë½ ë Y ìœ„ì¹˜ (optional)
        y_pos_bottom: í•˜ë‹¨ ì¹´ë©”ë¼ì—ì„œ ì†ê°€ë½ ë Y ìœ„ì¹˜ (optional)
        is_side_facing: ì†ë‚  ìƒíƒœ ì—¬ë¶€ (optional)
        finger_name: ì†ê°€ë½ ì´ë¦„ (optional)

    Returns:
        1: straight (í´ì§), 0: between (ì¤‘ê°„), -1: bent (êµ½í˜)
    """
    # ì†ê°€ë½ë³„ ì„ê³„ê°’ (ì‹±ê¸€ ê°ë„ ì „ìš©)
    if finger_name in ["Middle", "Ring"]:
        straight_threshold = (
            169 if finger_name == "Middle" else 160
        )  # ì¤‘ì§€: 169ë„, ì•½ì§€: 160ë„ ì´ìƒë§Œ Straight
        bent_threshold = 90 if is_side_facing else 55  # 55ë„ ì´í•˜ë§Œ Bent
    elif finger_name == "Pinky":
        # ì†Œì§€: 160ë„ ì´ìƒë§Œ Straight
        straight_threshold = 160
        bent_threshold = 90 if is_side_facing else 50
    else:
        # ê²€ì§€: ê¸°ë³¸ê°’
        straight_threshold = 165
        bent_threshold = 90 if is_side_facing else 50

    # ğŸ¯ Step 1: ì¸¡ë©´ ì¹´ë©”ë¼ë¡œ 1ì°¨ íŒì • (ì‹±ê¸€ ê°ë„ë§Œ)
    if angle_side >= straight_threshold:
        side_state = 1  # straight
    elif angle_side <= bent_threshold:
        side_state = -1  # bent
    else:
        side_state = 0  # between

    # ğŸ¯ Step 2: í•˜ë‹¨ ì¹´ë©”ë¼ ìœµí•© (ì‹±ê¸€ ê°ë„ë§Œ)
    if angle_bottom is not None:
        # í•˜ë‹¨ ì¹´ë©”ë¼ë„ ê°™ì€ ì„ê³„ê°’ ì ìš©
        bottom_straight_threshold = 160 if finger_name == "Pinky" else 170
        if angle_bottom >= bottom_straight_threshold:
            bottom_state = 1  # straight
        elif angle_bottom <= 50:
            bottom_state = -1  # bent
        else:
            bottom_state = 0  # between

        # ë‘ ì¹´ë©”ë¼ ì˜ê²¬ì´ ì¼ì¹˜í•˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if side_state == bottom_state:
            final_state = side_state
        # BENT íŒì • ì‹œ í•˜ë‹¨ ì¹´ë©”ë¼ ìš°ì„ 
        elif bottom_state == -1:
            final_state = -1  # í•˜ë‹¨ ì¹´ë©”ë¼ê°€ BENTë©´ BENTë¡œ ê²°ì •
        elif side_state == -1 and bottom_state != -1:
            final_state = -1  # ì¸¡ë©´ ì¹´ë©”ë¼ê°€ BENTë©´ BENTë¡œ ê²°ì •
        # ì˜ê²¬ì´ ë‹¤ë¥¸ ê²½ìš°
        # straight <-> between: between ìš°ì„  (ì• ë§¤í•˜ë©´ ì¤‘ê°„ìœ¼ë¡œ)
        elif (side_state == 1 and bottom_state == 0) or (
            side_state == 0 and bottom_state == 1
        ):
            final_state = 0
        # between <-> bent: between ìš°ì„ 
        elif side_state == 0 and bottom_state == -1:
            final_state = 0  # Betweenìœ¼ë¡œ íŒì •
        elif side_state == -1 and bottom_state == 0:
            final_state = 0  # Betweenìœ¼ë¡œ íŒì •
        # straight <-> bent: betweenìœ¼ë¡œ ë³´ì •
        elif side_state == 1 and bottom_state == -1:
            final_state = 0  # ì• ë§¤í•˜ë©´ ì¤‘ê°„
        elif side_state == -1 and bottom_state == 1:
            final_state = 0  # ì• ë§¤í•˜ë©´ ì¤‘ê°„
        else:
            final_state = side_state
    else:
        # Bottom ì •ë³´ ì—†ìœ¼ë©´ ì¸¡ë©´ë§Œìœ¼ë¡œ íŒë‹¨
        final_state = side_state

    # ğŸ¯ ì‹±ê¸€ ê°ë„ë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ ë°”ë¡œ ë°˜í™˜ (Lower ê°ë„ ì²˜ë¦¬ ì—†ìŒ)
    return final_state


def classify_finger_state_3way_side(
    angle_side,
    angle_bottom=None,
    y_pos_side=None,
    y_pos_bottom=None,
    is_side_facing=False,
    finger_name=None,
):
    """
    3ë‹¨ê³„ ì†ê°€ë½ ìƒíƒœ ë¶„ë¥˜ (ì¸¡ë©´ ì¹´ë©”ë¼ìš©): 1(straight) / 0(between) / -1(bent)

    Args:
        angle_side: ì¸¡ë©´ ì¹´ë©”ë¼ ì†ê°€ë½ ê°ë„
        angle_bottom: í•˜ë‹¨ ì¹´ë©”ë¼ ì†ê°€ë½ ê°ë„ (optional)
        y_pos_side: ì¸¡ë©´ ì¹´ë©”ë¼ì—ì„œ ì†ê°€ë½ ë Y ìœ„ì¹˜ (optional)
        y_pos_bottom: í•˜ë‹¨ ì¹´ë©”ë¼ì—ì„œ ì†ê°€ë½ ë Y ìœ„ì¹˜ (optional)
        is_side_facing: ì†ë‚  ìƒíƒœ ì—¬ë¶€ (optional, default: False)
        finger_name: ì†ê°€ë½ ì´ë¦„ (optional) - ì†ê°€ë½ë³„ ì„ê³„ê°’ ì ìš©

    Returns:
        1: straight (í´ì§), 0: between (ì¤‘ê°„), -1: bent (êµ½í˜)
    """
    # ì†ê°€ë½ë³„ë¡œ ë‹¤ë¥¸ ì„ê³„ê°’ ì ìš©
    # ì¤‘ì§€/ì•½ì§€ëŠ” ì¹´ë©”ë¼ ê°ë„ì— ë¯¼ê°í•˜ë¯€ë¡œ ë” ê´€ëŒ€í•œ ì„ê³„ê°’ ì‚¬ìš©
    if finger_name in ["Middle", "Ring"]:
        straight_threshold = (
            169 if finger_name == "Middle" else 160
        )  # ì¤‘ì§€: 169ë„, ì•½ì§€: 160ë„ ì´ìƒë§Œ Straight
        bent_threshold = 90 if is_side_facing else 55  # 55ë„ ì´í•˜ë§Œ Bent
    else:
        # ê²€ì§€/ì†Œì§€: ê¸°ë³¸ê°’
        straight_threshold = 165
        bent_threshold = 90 if is_side_facing else 50

    if angle_side >= straight_threshold:
        side_state = 1  # straight
    elif angle_side <= bent_threshold:
        side_state = -1  # bent
    else:
        side_state = 0  # between

    if angle_bottom is not None:
        # í•˜ë‹¨ ì¹´ë©”ë¼ë„ Between ë²”ìœ„ í™•ëŒ€
        if angle_bottom >= 170:
            bottom_state = 1  # straight
        elif angle_bottom <= 50:
            bottom_state = -1  # bent
        else:
            bottom_state = 0  # between

        # ë‘ ì¹´ë©”ë¼ ì˜ê²¬ì´ ì¼ì¹˜í•˜ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if side_state == bottom_state:
            return side_state

        # ì˜ê²¬ì´ ë‹¤ë¥¸ ê²½ìš°
        # straight <-> between: between ìš°ì„  (ì• ë§¤í•˜ë©´ ì¤‘ê°„ìœ¼ë¡œ)
        if (side_state == 1 and bottom_state == 0) or (
            side_state == 0 and bottom_state == 1
        ):
            return 0
        # between <-> bent: between ìš°ì„  (Between ë²”ìœ„ë¥¼ ë„“í˜”ìœ¼ë¯€ë¡œ Between ì‹ ë¢°)
        elif side_state == 0 and bottom_state == -1:
            return 0  # Betweenìœ¼ë¡œ íŒì •
        elif side_state == -1 and bottom_state == 0:
            return 0  # Betweenìœ¼ë¡œ íŒì •
        # straight <-> bent: betweenìœ¼ë¡œ ë³´ì • (ê·¹ë‹¨ì  ì°¨ì´ëŠ” ì¤‘ê°„ìœ¼ë¡œ)
        elif side_state == 1 and bottom_state == -1:
            return 0  # ì• ë§¤í•˜ë©´ ì¤‘ê°„
        elif side_state == -1 and bottom_state == 1:
            return 0  # ì• ë§¤í•˜ë©´ ì¤‘ê°„

    # Bottom ì •ë³´ ì—†ìœ¼ë©´ ì¸¡ë©´ë§Œìœ¼ë¡œ íŒë‹¨
    return side_state


def classify_thumb_position(camera_state):
    """í•˜ë‹¨ ì¹´ë©”ë¼ì˜ ì €ì¥ëœ íŒ ì¢Œí‘œì™€ ì •ê·œí™” ê°’ìœ¼ë¡œ ì—„ì§€ ìœ„ì¹˜ë¥¼ ê·œì¹™ ê¸°ë°˜(E/N/M)ìœ¼ë¡œ íŒì •í•©ë‹ˆë‹¤.

    ë°˜í™˜ê°’: (code, text) where code: 0=NEUTRAL, 1=ON_TOP, 2=BETWEEN
    ê°„ë‹¨ ê·œì¹™:
      - nd_middle <= 0.08 -> ON_TOP
      - nd_index <= 0.06 or nd_ring <= 0.06 -> BETWEEN
      - otherwise -> NEUTRAL

    ì¹´ë©”ë¼ ìƒíƒœì— palm_width_pixels ë˜ëŠ” í”½ì…€ ê±°ë¦¬ê°€ ì—†ì„ ê²½ìš° í”½ì…€ ê¸°ì¤€ ê°’ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
    ì•ˆì •í™”ë¥¼ ìœ„í•´ ê°™ì€ ê²°ê³¼ê°€ 3í”„ë ˆì„ ì—°ì†ì¼ ë•Œë§Œ ì¹´ìš´íŠ¸ê°€ ì¦ê°€í•©ë‹ˆë‹¤n"""
    # ê¸°ë³¸
    NEUTRAL = 0
    ON_TOP = 1
    BETWEEN = 2

    # í•„ìš”í•œ ê°’ ì½ê¸°
    tt = getattr(camera_state, "thumb_tip_coords", None)
    it = getattr(camera_state, "index_tip_coords", None)
    mt = getattr(camera_state, "middle_tip_coords", None)
    rt = getattr(camera_state, "ring_tip_coords", None)
    palm_w = getattr(camera_state, "palm_width_pixels", None)

    if not (tt and it and mt and rt):
        return NEUTRAL, "NEUTRAL"

    tx, ty = tt
    ix, iy = it
    mx, my = mt
    rx, ry = rt

    d_index = math.hypot(tx - ix, ty - iy)
    d_middle = math.hypot(tx - mx, ty - my)
    d_ring = math.hypot(tx - rx, ty - ry)

    # ì •ê·œí™” ê±°ë¦¬ ê³„ì‚°
    nd_index = nd_middle = nd_ring = None
    if palm_w and palm_w > 1e-6:
        nd_index = d_index / palm_w
        nd_middle = d_middle / palm_w
        nd_ring = d_ring / palm_w

    # ê·œì¹™ ì ìš© (ì •ê·œí™” ê°’ ìš°ì„ )
    result = NEUTRAL
    result_text = "NEUTRAL"
    if nd_middle is not None:
        if nd_middle <= 0.08:
            result = ON_TOP
            result_text = "ON_TOP"
        elif (nd_index is not None and nd_index <= 0.06) or (
            nd_ring is not None and nd_ring <= 0.06
        ):
            result = BETWEEN
            result_text = "BETWEEN"
        else:
            result = NEUTRAL
            result_text = "NEUTRAL"
    else:
        # í”½ì…€ ê°’ìœ¼ë¡œ ëŒ€ì²´ ì¡°ê±´
        if d_middle <= 25:
            result = ON_TOP
            result_text = "ON_TOP"
        elif d_index <= 20 or d_ring <= 20:
            result = BETWEEN
            result_text = "BETWEEN"
        else:
            result = NEUTRAL
            result_text = "NEUTRAL"

    # ì•ˆì •ì„±(3í”„ë ˆì„) ì¹´ìš´í„° ê´€ë¦¬
    last = getattr(camera_state, "last_thumb_position", None)
    count = getattr(camera_state, "thumb_position_count", 0)
    if last == result_text:
        count = min(count + 1, 10)
    else:
        count = 1
    camera_state.last_thumb_position = result_text
    camera_state.thumb_position_count = count

    # ì‹¤ì œ ë°˜í™˜ì€ count >= 1 ì´ë©´ ë°”ë¡œ ë°˜í™˜ (ì§§ì€ ì•ˆì •ì„± ì ìš©)
    return result, result_text


def is_thumb_between_fingers(camera_state):
    """ì—„ì§€ê°€ ì†ê°€ë½ ì‚¬ì´ì— ìˆëŠ”ì§€ íŒì •: z ê°’ê³¼ x,y ìœ„ì¹˜ë¥¼ í•¨ê»˜ ì‚¬ìš©."""
    tt = getattr(camera_state, "thumb_tip_coords", None)
    it = getattr(camera_state, "index_tip_coords", None)
    mt = getattr(camera_state, "middle_tip_coords", None)
    rt = getattr(camera_state, "ring_tip_coords", None)

    if not (tt and it and mt and rt):
        return False

    tx, ty = tt
    ix, iy = it
    mx, my = mt
    rx, ry = rt

    # check x between index and ring (loose check)
    min_x = min(ix, rx)
    max_x = max(ix, rx)
    in_x_band = min_x - 5 <= tx <= max_x + 5

    # use z-values: thumb_tip_z closer to finger tips z (i.e., between) -> small relative
    rel = getattr(camera_state, "thumb_rel_to_fingertips_norm", None)
    # rel ~ 0 => same plane; negative => thumb closer to camera (smaller z) depending on MP coord
    z_close = False
    if rel is not None:
        # threshold: abs(rel) < 0.03 considered same plane
        z_close = abs(rel) <= 0.03

    return in_x_band and z_close


def check_thumb_between_fingers_side(camera_state, hand_landmarks, w, h):
    """ì¸¡ë©´ ì¹´ë©”ë¼ì—ì„œ ì—„ì§€ê°€ ì†ê°€ë½ ì‚¬ì´ì— ë¼ì–´ìˆëŠ”ì§€ íŒì •.

    PIP(ë‘ ë²ˆì§¸ ë§ˆë””) ê¸°ë°˜ ì„¸ê·¸ë¨¼íŠ¸ ì •ì˜:
    - ì—„ì§€ TIPì´ ê²€ì§€ PIP - ì¤‘ì§€ PIP ì‚¬ì´: IM (ê²€ì§€-ì¤‘ì§€ ì‚¬ì´) -> T
    - ì—„ì§€ TIPì´ ì¤‘ì§€ PIP - ì•½ì§€ PIP ì‚¬ì´: MR (ì¤‘ì§€-ì•½ì§€ ì‚¬ì´) -> N
    - ì—„ì§€ TIPì´ ì•½ì§€ PIP - ì†Œì§€ PIP ì‚¬ì´: RP (ì•½ì§€-ì†Œì§€ ì‚¬ì´) -> M

    Args:
        camera_state: ì¹´ë©”ë¼ ìƒíƒœ ê°ì²´
        hand_landmarks: MediaPipe ì† ëœë“œë§ˆí¬
        w, h: ì´ë¯¸ì§€ ë„ˆë¹„, ë†’ì´

    Returns:
        (is_between: bool, segment: str, details: dict)
    """
    try:
        # Thumb TIP
        thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]
        tx, ty = int(thumb_tip.x * w), int(thumb_tip.y * h)

        # Finger PIPs (ë‘ ë²ˆì§¸ ë§ˆë””)
        index_pip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP]
        middle_pip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP]
        ring_pip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_PIP]
        pinky_pip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_PIP]

        # Finger TIPs (ë ë§ˆë””) - Xì¶• ë²”ìœ„ ì²´í¬ìš©
        index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]
        middle_tip = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]
        ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]
        pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]

        # PIP ì¢Œí‘œ
        ix_pip, iy_pip = int(index_pip.x * w), int(index_pip.y * h)
        mx_pip, my_pip = int(middle_pip.x * w), int(middle_pip.y * h)
        rx_pip, ry_pip = int(ring_pip.x * w), int(ring_pip.y * h)
        px_pip, py_pip = int(pinky_pip.x * w), int(pinky_pip.y * h)

        # TIP ì¢Œí‘œ (Xì¶• ë²”ìœ„ìš©)
        ix_tip, iy_tip = int(index_tip.x * w), int(index_tip.y * h)
        mx_tip, my_tip = int(middle_tip.x * w), int(middle_tip.y * h)
        rx_tip, ry_tip = int(ring_tip.x * w), int(ring_tip.y * h)
        px_tip, py_tip = int(pinky_tip.x * w), int(pinky_tip.y * h)

    except Exception as e:
        return False, "ERROR", {"error": str(e)}

    # PIP ê¸°ë°˜ ì„¸ê·¸ë¨¼íŠ¸ Y ë²”ìœ„ ì •ì˜
    im_y_min = min(iy_pip, my_pip)
    im_y_max = max(iy_pip, my_pip)
    mr_y_min = min(my_pip, ry_pip)
    mr_y_max = max(my_pip, ry_pip)
    rp_y_min = min(ry_pip, py_pip)
    rp_y_max = max(ry_pip, py_pip)

    # ì„¸ê·¸ë¨¼íŠ¸ Y ì¤‘ì‹¬ì  ê³„ì‚°
    im_y_center = (im_y_min + im_y_max) / 2
    mr_y_center = (mr_y_min + mr_y_max) / 2
    rp_y_center = (rp_y_min + rp_y_max) / 2

    # ì—¬ìœ  ë²”ìœ„ (PIP ê°„ ê±°ë¦¬ì˜ ì¼ì • ë¹„ìœ¨ë¡œ ì„¤ì •)
    im_height = abs(my_pip - iy_pip)
    mr_height = abs(ry_pip - my_pip)
    rp_height = abs(py_pip - ry_pip)

    # ìµœì†Œ ë†’ì´ ì„¤ì • (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
    MIN_HEIGHT = 5.0  # ìµœì†Œ 5 í”½ì…€
    if im_height < MIN_HEIGHT:
        im_height = MIN_HEIGHT
    if mr_height < MIN_HEIGHT:
        mr_height = MIN_HEIGHT
    if rp_height < MIN_HEIGHT:
        rp_height = MIN_HEIGHT

    # ì—¬ìœ  ë²”ìœ„ (PIP ê°„ ê±°ë¦¬ì˜ ì¼ì • ë¹„ìœ¨ë¡œ ì„¤ì •)
    # IM(T ì œìŠ¤ì²˜)ëŠ” MRê³¼ êµ¬ë¶„ì„ ìœ„í•´ ë§ˆì§„ì„ ë” ë„“ê²Œ ì„¤ì •
    # RP(M ì œìŠ¤ì²˜)ëŠ” ë¼ìš°ê¸° ì–´ë ¤ìš°ë¯€ë¡œ ë§ˆì§„ì„ ë” í¬ê²Œ ì„¤ì •
    im_margin = im_height * 0.4  # 40% ì—¬ìœ  (T ì œìŠ¤ì²˜ ì•ˆì •ì„± í–¥ìƒ)
    mr_margin = mr_height * 0.3  # 30% ì—¬ìœ 
    rp_margin = rp_height * 0.5  # 50% ì—¬ìœ  (M ì œìŠ¤ì²˜ ì•ˆì •ì„± í–¥ìƒ)

    # Xì¶• ì²´í¬: ì—„ì§€ê°€ ì†ê°€ë½ë“¤ TIP ê·¼ì²˜ì— ìˆì–´ì•¼ í•¨
    fingers_x_min = min(ix_tip, mx_tip, rx_tip, px_tip)
    fingers_x_max = max(ix_tip, mx_tip, rx_tip, px_tip)
    x_margin = 40  # í”½ì…€ ë‹¨ìœ„
    in_x_range = (fingers_x_min - x_margin) <= tx <= (fingers_x_max + x_margin)

    if not in_x_range:
        return (
            False,
            "OUT_OF_X_RANGE",
            {"tx": tx, "x_range": (fingers_x_min, fingers_x_max), "margin": x_margin},
        )

    # ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ í›„ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ì¤‘ì‹¬ìœ¼ë¡œë¶€í„° ê°€ì¥ ê°€ê¹Œìš´ ê²ƒì„ ì„ íƒ
    candidates = []

    # IM ì„¸ê·¸ë¨¼íŠ¸ ì²´í¬ (ê²€ì§€ PIP - ì¤‘ì§€ PIP ì‚¬ì´)
    if (im_y_min - im_margin) <= ty <= (im_y_max + im_margin):
        distance_from_center = abs(ty - im_y_center)
        denominator = im_height / 2 + im_margin
        confidence = (
            1.0 - (distance_from_center / denominator) if denominator > 0 else 0.0
        )
        confidence = max(0.0, min(1.0, confidence))

        candidates.append(
            {
                "segment": "IM",
                "distance": distance_from_center,
                "confidence": confidence,
                "details": {
                    "ty": ty,
                    "segment_y_range": (im_y_min, im_y_max),
                    "segment_y_center": im_y_center,
                    "distance_from_center": distance_from_center,
                    "confidence": confidence,
                    "pip_coords": {
                        "index": (ix_pip, iy_pip),
                        "middle": (mx_pip, my_pip),
                    },
                },
            }
        )

    # MR ì„¸ê·¸ë¨¼íŠ¸ ì²´í¬ (ì¤‘ì§€ PIP - ì•½ì§€ PIP ì‚¬ì´)
    if (mr_y_min - mr_margin) <= ty <= (mr_y_max + mr_margin):
        distance_from_center = abs(ty - mr_y_center)
        denominator = mr_height / 2 + mr_margin
        confidence = (
            1.0 - (distance_from_center / denominator) if denominator > 0 else 0.0
        )
        confidence = max(0.0, min(1.0, confidence))

        candidates.append(
            {
                "segment": "MR",
                "distance": distance_from_center,
                "confidence": confidence,
                "details": {
                    "ty": ty,
                    "segment_y_range": (mr_y_min, mr_y_max),
                    "segment_y_center": mr_y_center,
                    "distance_from_center": distance_from_center,
                    "confidence": confidence,
                    "pip_coords": {
                        "middle": (mx_pip, my_pip),
                        "ring": (rx_pip, ry_pip),
                    },
                },
            }
        )

    # RP ì„¸ê·¸ë¨¼íŠ¸ ì²´í¬ (ì•½ì§€ PIP - ì†Œì§€ PIP ì‚¬ì´)
    if (rp_y_min - rp_margin) <= ty <= (rp_y_max + rp_margin):
        distance_from_center = abs(ty - rp_y_center)
        denominator = rp_height / 2 + rp_margin
        confidence = (
            1.0 - (distance_from_center / denominator) if denominator > 0 else 0.0
        )
        confidence = max(0.0, min(1.0, confidence))

        candidates.append(
            {
                "segment": "RP",
                "distance": distance_from_center,
                "confidence": confidence,
                "details": {
                    "ty": ty,
                    "segment_y_range": (rp_y_min, rp_y_max),
                    "segment_y_center": rp_y_center,
                    "distance_from_center": distance_from_center,
                    "confidence": confidence,
                    "pip_coords": {"ring": (rx_pip, ry_pip), "pinky": (px_pip, py_pip)},
                },
            }
        )

    # í›„ë³´ê°€ ìˆìœ¼ë©´ ì¤‘ì‹¬ìœ¼ë¡œë¶€í„° ê°€ì¥ ê°€ê¹Œìš´ ê²ƒ ì„ íƒ
    if candidates:
        # ì¤‘ì‹¬ìœ¼ë¡œë¶€í„°ì˜ ê±°ë¦¬ê°€ ê°€ì¥ ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ì„ íƒ
        best = min(candidates, key=lambda x: x["distance"])
        return (True, best["segment"], best["details"])

    # ì–´ëŠ ë²”ìœ„ì—ë„ í•´ë‹¹í•˜ì§€ ì•ŠìŒ
    return (
        False,
        "NONE",
        {
            "ty": ty,
            "im_range": (im_y_min - im_margin, im_y_max + im_margin),
            "mr_range": (mr_y_min - mr_margin, mr_y_max + mr_margin),
            "rp_range": (rp_y_min - rp_margin, rp_y_max + rp_margin),
            "im_center": im_y_center,
            "mr_center": mr_y_center,
            "rp_center": rp_y_center,
        },
    )


def is_thumb_between_fingers_3d(camera_state):
    """ì†ê°€ë½ ì‚¬ì´ íŒì •: 2Dë¡œ ì—„ì§€ì™€ ê° ì†ê°€ë½ ì„ ë¶„ì˜ ìµœë‹¨ê±°ë¦¬ íˆ¬ì˜ì„ êµ¬í•˜ê³ ,
    í•´ë‹¹ íˆ¬ì˜ ìœ„ì¹˜ì˜ zë¥¼ ì„ í˜• ë³´ê°„í•˜ì—¬ ì—„ì§€ì™€ì˜ z ì°¨ì´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

    3ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì²´í¬:
    - IM: Index-Middle (ê²€ì§€-ì¤‘ì§€ ì‚¬ì´) -> T ì œìŠ¤ì²˜
    - MR: Middle-Ring (ì¤‘ì§€-ì•½ì§€ ì‚¬ì´) -> N ì œìŠ¤ì²˜
    - RP: Ring-Pinky (ì•½ì§€-ì†Œì§€ ì‚¬ì´) -> M ì œìŠ¤ì²˜

    ë°˜í™˜: (between_bool, details_dict)
    details_dict: { 'seg': 'IM'/'MR'/'RP', 't': t, 'nd': normalized_2d_dist, 'nz': normalized_z_diff }
    """
    tt = getattr(camera_state, "thumb_tip_coords", None)
    it = getattr(camera_state, "index_tip_coords", None)
    mt = getattr(camera_state, "middle_tip_coords", None)
    rt = getattr(camera_state, "ring_tip_coords", None)
    pt = getattr(camera_state, "pinky_tip_coords", None)

    tz = getattr(camera_state, "thumb_tip_z", None)
    iz = getattr(camera_state, "index_tip_z", None)
    mz = getattr(camera_state, "middle_tip_z", None)
    rz = getattr(camera_state, "ring_tip_z", None)
    pz = getattr(camera_state, "pinky_tip_z", None)

    palm_w = getattr(camera_state, "palm_width_pixels", None)
    hand_size_3d = getattr(camera_state, "hand_size_3d", None)

    # í•„ìš” ë°ì´í„° ì—†ìœ¼ë©´ ì´ì „ ê°„ë‹¨ íŒì •ìœ¼ë¡œ í´ë°±
    if not (tt and it and mt and rt and pt):
        return is_thumb_between_fingers(camera_state), {"reason": "missing_2d"}

    # í—¬í¼: 2D point-to-segment projection
    def proj_t_and_dist(p, a, b):
        ax, ay = a
        bx, by = b
        px, py = p
        dx, dy = bx - ax, by - ay
        denom = dx * dx + dy * dy
        if denom < 1e-6:
            return 0.0, math.hypot(px - ax, py - ay)
        t = ((px - ax) * dx + (py - ay) * dy) / denom
        t_clamped = max(0.0, min(1.0, t))
        projx = ax + t_clamped * dx
        projy = ay + t_clamped * dy
        dist = math.hypot(px - projx, py - projy)
        return t_clamped, dist

    thumb_p = tt

    # Check 3 finger-tip segments
    im_t, im_d = proj_t_and_dist(thumb_p, it, mt)  # Index-Middle
    mr_t, mr_d = proj_t_and_dist(thumb_p, mt, rt)  # Middle-Ring
    rp_t, rp_d = proj_t_and_dist(thumb_p, rt, pt)  # Ring-Pinky

    # Normalize distances
    if palm_w and palm_w > 1e-6:
        nd_im = im_d / palm_w
        nd_mr = mr_d / palm_w
        nd_rp = rp_d / palm_w
    else:
        nd_im = im_d
        nd_mr = mr_d
        nd_rp = rp_d

    # Interpolate z at projection if available
    def interp_z(t, z1, z2):
        if z1 is None or z2 is None:
            return None
        return z1 + t * (z2 - z1)

    im_interp_z = interp_z(im_t, iz, mz)
    mr_interp_z = interp_z(mr_t, mz, rz)
    rp_interp_z = interp_z(rp_t, rz, pz)

    # Calculate normalized z differences
    nz_im = None
    nz_mr = None
    nz_rp = None

    if (
        tz is not None
        and im_interp_z is not None
        and hand_size_3d
        and hand_size_3d > 1e-6
    ):
        nz_im = (tz - im_interp_z) / hand_size_3d
    if (
        tz is not None
        and mr_interp_z is not None
        and hand_size_3d
        and hand_size_3d > 1e-6
    ):
        nz_mr = (tz - mr_interp_z) / hand_size_3d
    if (
        tz is not None
        and rp_interp_z is not None
        and hand_size_3d
        and hand_size_3d > 1e-6
    ):
        nz_rp = (tz - rp_interp_z) / hand_size_3d

    # Thresholds (ê²½í—˜ì ): nd < 0.06 and abs(nz) < 0.04 and t in [0,1]
    between = False
    chosen = None

    # Check all three segments (ìš°ì„ ìˆœìœ„: IM -> MR -> RP)
    if (
        nd_im is not None
        and nd_im <= 0.06
        and nz_im is not None
        and abs(nz_im) <= 0.04
        and 0.0 <= im_t <= 1.0
    ):
        between = True
        chosen = ("IM", im_t, nd_im, nz_im)
    elif (
        nd_mr is not None
        and nd_mr <= 0.06
        and nz_mr is not None
        and abs(nz_mr) <= 0.04
        and 0.0 <= mr_t <= 1.0
    ):
        between = True
        chosen = ("MR", mr_t, nd_mr, nz_mr)
    elif (
        nd_rp is not None
        and nd_rp <= 0.06
        and nz_rp is not None
        and abs(nz_rp) <= 0.04
        and 0.0 <= rp_t <= 1.0
    ):
        between = True
        chosen = ("RP", rp_t, nd_rp, nz_rp)

    if not between:
        # fallback: use simple rel check, but still show nd/nz values from closest segment
        simple = is_thumb_between_fingers(camera_state)
        between = simple

        # ê°€ì¥ ê°€ê¹Œìš´ ì„¸ê·¸ë¨¼íŠ¸ ì„ íƒ (nd ê°’ ê¸°ì¤€)
        candidates = []
        if nd_im is not None:
            candidates.append(("fallback_IM", im_t, nd_im, nz_im, nd_im))
        if nd_mr is not None:
            candidates.append(("fallback_MR", mr_t, nd_mr, nz_mr, nd_mr))
        if nd_rp is not None:
            candidates.append(("fallback_RP", rp_t, nd_rp, nz_rp, nd_rp))

        if candidates:
            # nd ê°’ì´ ê°€ì¥ ì‘ì€ ì„¸ê·¸ë¨¼íŠ¸ ì„ íƒ
            closest = min(candidates, key=lambda x: x[4])
            chosen = closest[:4]  # (seg, t, nd, nz)
        else:
            chosen = ("fallback", 0.0, None, None)

    details = {
        "seg": chosen[0] if chosen else "none",
        "t": chosen[1] if chosen else 0.0,
        "nd": chosen[2] if chosen else None,
        "nz": chosen[3] if chosen else None,
    }
    return between, details


def check_index_middle_distance(camera_state, hand_size_3d=None):
    """
    ê²€ì§€ì™€ ì¤‘ì§€ TIP ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ì—¬ ë¶™ì–´ìˆëŠ”ì§€/ë–¨ì–´ì ¸ìˆëŠ”ì§€ íŒë³„í•©ë‹ˆë‹¤.

    Args:
        camera_state: ì¹´ë©”ë¼ ìƒíƒœ (index_tip_coords, middle_tip_coords í•„ìš”)
        hand_size_3d: ì† í¬ê¸° (ì •ê·œí™”ìš©, ì—†ìœ¼ë©´ í”½ì…€ ê±°ë¦¬ ì‚¬ìš©)

    Returns:
        tuple: (is_together: bool, distance: float, normalized_distance: float or None)
            - is_together: Trueë©´ ë¶™ì–´ìˆìŒ, Falseë©´ ë–¨ì–´ì ¸ìˆìŒ
            - distance: í”½ì…€ ë‹¨ìœ„ ê±°ë¦¬
            - normalized_distance: ì† í¬ê¸°ë¡œ ì •ê·œí™”ëœ ê±°ë¦¬ (hand_size_3d ìˆì„ ë•Œë§Œ)
    """
    global INDEX_MIDDLE_DISTANCE_THRESHOLD

    it = getattr(camera_state, "index_tip_coords", None)
    mt = getattr(camera_state, "middle_tip_coords", None)

    if it is None or mt is None:
        return None, None, None

    # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
    ix, iy = it
    mx, my = mt
    distance = math.sqrt((ix - mx) ** 2 + (iy - my) ** 2)

    # ì† í¬ê¸°ë¡œ ì •ê·œí™” (ìˆìœ¼ë©´)
    normalized_distance = None
    if hand_size_3d is not None and hand_size_3d > 0:
        normalized_distance = distance / hand_size_3d

    # ì„ê³„ê°’ ì„¤ì • (ì •ê·œí™”ëœ ê±°ë¦¬ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í”½ì…€ ê±°ë¦¬)
    if normalized_distance is not None:
        # ì •ê·œí™”ëœ ê±°ë¦¬ ê¸°ì¤€: ì „ì—­ ì„ê³„ê°’ ì‚¬ìš©
        is_together = normalized_distance <= INDEX_MIDDLE_DISTANCE_THRESHOLD
    else:
        # í”½ì…€ ê±°ë¦¬ ê¸°ì¤€: 30 í”½ì…€ ì´í•˜ë©´ ë¶™ì–´ìˆìŒ (fallback)
        threshold = 30.0
        is_together = distance <= threshold

    return is_together, distance, normalized_distance


def check_extended_fingers_together(camera_state, finger_states, hand_size_3d=None):
    """
    í´ì§„(straight=1) ì†ê°€ë½ë“¤ì´ ëª¨ë‘ ë¶™ì–´ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

    Args:
        camera_state: ì¹´ë©”ë¼ ìƒíƒœ (ê° ì†ê°€ë½ tip_coords í•„ìš”)
        finger_states: ì†ê°€ë½ ìƒíƒœ dict {finger_name: state}
        hand_size_3d: ì† í¬ê¸° (ì •ê·œí™”ìš©, ì„ íƒì )

    Returns:
        dict: {
            "all_together": bool,  # ëª¨ë“  í´ì§„ ì†ê°€ë½ì´ ë¶™ì–´ìˆìœ¼ë©´ True
            "extended_fingers": list,  # í´ì§„ ì†ê°€ë½ ë¦¬ìŠ¤íŠ¸
            "pairwise_distances": dict,  # ê° ìŒì˜ ê±°ë¦¬
            "separated_pairs": list  # ë–¨ì–´ì§„ ìŒ ë¦¬ìŠ¤íŠ¸
        }
    """
    # 1. í´ì§„ ì†ê°€ë½(state=1) ì°¾ê¸° (ì—„ì§€ ì œì™¸)
    extended_fingers = [
        name
        for name in ["Index", "Middle", "Ring", "Pinky"]
        if finger_states.get(name) == 1
    ]

    # 2. í´ì§„ ì†ê°€ë½ì´ 2ê°œ ë¯¸ë§Œì´ë©´ ì²´í¬ ë¶ˆí•„ìš” (í•­ìƒ ë¶™ì–´ìˆë‹¤ê³  ê°„ì£¼)
    if len(extended_fingers) < 2:
        return {
            "all_together": True,
            "extended_fingers": extended_fingers,
            "pairwise_distances": {},
            "separated_pairs": [],
        }

    # 3. ëª¨ë“  ì¸ì ‘ ì†ê°€ë½ ìŒì˜ ê±°ë¦¬ ê³„ì‚°
    threshold = 50.0  # í”½ì…€ ê±°ë¦¬ ì„ê³„ê°’ (ëª¨ë“  ìŒ í†µì¼)
    pairwise_distances = {}
    separated_pairs = []

    finger_to_attr = {
        "Index": "index_tip_coords",
        "Middle": "middle_tip_coords",
        "Ring": "ring_tip_coords",
        "Pinky": "pinky_tip_coords",
    }

    for i in range(len(extended_fingers) - 1):
        finger1 = extended_fingers[i]
        finger2 = extended_fingers[i + 1]

        pair_key = f"{finger1}-{finger2}"

        # Ring-Pinky ìŒì€ íŠ¹ë³„ ì²˜ë¦¬: Ring DIPê³¼ Pinky TIP ë¹„êµ
        if pair_key == "Ring-Pinky":
            ring_dip_coords = getattr(camera_state, "ring_dip_coords", None)
            pinky_tip_coords = getattr(camera_state, "pinky_tip_coords", None)

            if ring_dip_coords and pinky_tip_coords:
                x1, y1 = ring_dip_coords
                x2, y2 = pinky_tip_coords
                distance = math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)

                pairwise_distances[pair_key] = distance
                pair_threshold = 50.0

                if distance > pair_threshold:
                    separated_pairs.append(pair_key)
        else:
            # ë‹¤ë¥¸ ìŒì€ TIP ëŒ€ TIP ë¹„êµ
            coords1 = getattr(camera_state, finger_to_attr[finger1], None)
            coords2 = getattr(camera_state, finger_to_attr[finger2], None)

            if coords1 and coords2:
                x1, y1 = coords1
                x2, y2 = coords2
                distance = math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)

                pairwise_distances[pair_key] = distance
                pair_threshold = threshold

                # ì„ê³„ê°’ë³´ë‹¤ í¬ë©´ ë–¨ì–´ì§„ ê²ƒìœ¼ë¡œ íŒì •
                if distance > pair_threshold:
                    separated_pairs.append(pair_key)

    # 4. ëª¨ë“  ì¸ì ‘ ìŒì´ ë¶™ì–´ìˆìœ¼ë©´ True
    all_together = len(separated_pairs) == 0

    return {
        "all_together": all_together,
        "extended_fingers": extended_fingers,
        "pairwise_distances": pairwise_distances,
        "separated_pairs": separated_pairs,
    }


def check_thumb_touching_fingers(camera_state, hand_size_3d=None):
    """
    ì—„ì§€ TIPì´ ê²€ì§€/ì¤‘ì§€/ì•½ì§€/ì†Œì§€ TIPê³¼ ì ‘ì´‰í–ˆëŠ”ì§€ ê°ì§€í•©ë‹ˆë‹¤.

    Args:
        camera_state: ì¹´ë©”ë¼ ìƒíƒœ (thumb_tip_coords, ë‹¤ë¥¸ ì†ê°€ë½ tip_coords í•„ìš”)
        hand_size_3d: ì† í¬ê¸° (ì •ê·œí™”ìš©)

    Returns:
        dict: {
            "touching": bool (í•˜ë‚˜ë¼ë„ ì ‘ì´‰í•˜ë©´ True),
            "touched_finger": str or None (ì ‘ì´‰í•œ ì†ê°€ë½ ì´ë¦„),
            "distances": dict (ê° ì†ê°€ë½ë³„ ì •ê·œí™”ëœ ê±°ë¦¬),
            "min_distance": float (ê°€ì¥ ê°€ê¹Œìš´ ê±°ë¦¬)
        }
    """
    global THUMB_TOUCH_THRESHOLD

    tt = getattr(camera_state, "thumb_tip_coords", None)
    it = getattr(camera_state, "index_tip_coords", None)
    mt = getattr(camera_state, "middle_tip_coords", None)
    rt = getattr(camera_state, "ring_tip_coords", None)
    pt = getattr(camera_state, "pinky_tip_coords", None)

    if tt is None:
        return {
            "touching": False,
            "touched_finger": None,
            "distances": {},
            "min_distance": None,
        }

    tx, ty = tt
    fingers = {"Index": it, "Middle": mt, "Ring": rt, "Pinky": pt}

    distances = {}
    normalized_distances = {}

    # ê° ì†ê°€ë½ê³¼ì˜ ê±°ë¦¬ ê³„ì‚°
    for finger_name, finger_coords in fingers.items():
        if finger_coords is not None:
            fx, fy = finger_coords
            distance = math.sqrt((tx - fx) ** 2 + (ty - fy) ** 2)
            distances[finger_name] = distance
            # í”½ì…€ ê±°ë¦¬ë¥¼ ì§ì ‘ ì‚¬ìš© (ì •ê·œí™”í•˜ì§€ ì•ŠìŒ)
            normalized_distances[finger_name] = distance

    # ê°€ì¥ ê°€ê¹Œìš´ ì†ê°€ë½ ì°¾ê¸°
    touching = False
    touched_finger = None
    min_distance = None

    if normalized_distances:
        # ê±°ë¦¬ê°€ ìˆëŠ” ì†ê°€ë½ë“¤ë§Œ í™•ì¸
        valid_fingers = {k: v for k, v in normalized_distances.items() if v is not None}

        if valid_fingers:
            # ê°€ì¥ ê°€ê¹Œìš´ ì†ê°€ë½
            closest_finger = min(valid_fingers.items(), key=lambda x: x[1])
            touched_finger = closest_finger[0]
            min_distance = closest_finger[1]

            # ì„ê³„ê°’ ì´í•˜ë©´ ì ‘ì´‰ìœ¼ë¡œ íŒì • (í”½ì…€ ê±°ë¦¬ ê¸°ì¤€)
            if min_distance <= THUMB_TOUCH_THRESHOLD:
                touching = True

    return {
        "touching": touching,
        "touched_finger": touched_finger if touching else None,
        "distances": normalized_distances,
        "min_distance": min_distance,
    }


def is_weapon_gesture(gesture_name):
    """ë¬´ê¸° ì œìŠ¤ì²˜ì¸ì§€ í™•ì¸í•˜ëŠ” í—¬í¼ í•¨ìˆ˜ (ì¦‰ì‹œ ì „ì†¡ìš© - Fire/Reloadë§Œ)"""
    if gesture_name is None:
        return False
    # SGì™€ S1ì€ ì¼ë°˜ ì œìŠ¤ì²˜ì²˜ëŸ¼ ì•ˆì •í™” ì‹œê°„ ì ìš©
    weapon_keywords = ["Fire", "Reload"]
    return any(keyword in gesture_name for keyword in weapon_keywords)


def classify_gesture_from_pattern_stabilized(
    integrated_states, bottom_camera_state, side_camera_state
):
    """
    ì†ê°€ë½ ìƒíƒœ íŒ¨í„´ìœ¼ë¡œ ì œìŠ¤ì²˜ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    0.5ì´ˆ ë™ì•ˆ ë™ì¼í•œ ìì„¸ê°€ ìœ ì§€ë˜ë©´ í•´ë‹¹ ì œìŠ¤ì²˜ë¡œ íŒë‹¨í•©ë‹ˆë‹¤.
    """
    global current_gesture_candidate, gesture_start_time, stable_gesture

    # í˜„ì¬ ì œìŠ¤ì²˜ í›„ë³´ ê³„ì‚°
    candidate_gesture = classify_gesture_from_pattern(
        integrated_states, bottom_camera_state, side_camera_state
    )

    current_time = time.time()

    # ìƒˆë¡œìš´ ì œìŠ¤ì²˜ í›„ë³´ê°€ ê°ì§€ë˜ì—ˆì„ ë•Œ
    if candidate_gesture != current_gesture_candidate:
        current_gesture_candidate = candidate_gesture
        gesture_start_time = current_time

        # ë¬´ê¸° ì œìŠ¤ì²˜(Fire/Reload)ëŠ” ì¦‰ì‹œ ì „ì†¡
        if is_weapon_gesture(candidate_gesture):
            send_gesture_to_unity(candidate_gesture)
            return candidate_gesture
        else:
            # ì¼ë°˜ ì œìŠ¤ì²˜ëŠ” ì•ˆì •í™” í•„ìš”
            send_no_gesture_to_unity()
            return None

    # ë™ì¼í•œ ì œìŠ¤ì²˜ í›„ë³´ê°€ ê³„ì† ìœ ì§€ë˜ê³  ìˆì„ ë•Œ
    if candidate_gesture is not None and gesture_start_time is not None:
        time_elapsed = current_time - gesture_start_time

        # ë¬´ê¸° ì œìŠ¤ì²˜ëŠ” ê³„ì† ì „ì†¡ (ì•ˆì •í™” ì‹œê°„ ë¬´ê´€)
        if is_weapon_gesture(candidate_gesture):
            send_gesture_to_unity(candidate_gesture)
            return candidate_gesture

        # ì¼ë°˜ ì œìŠ¤ì²˜ëŠ” 0.3ì´ˆ ì´ìƒ ìœ ì§€ë˜ë©´ ì•ˆì •ëœ ì œìŠ¤ì²˜ë¡œ íŒë‹¨
        if time_elapsed >= GESTURE_STABILIZATION_TIME:
            stable_gesture = candidate_gesture
            # Unityë¡œ ì•ˆì •ëœ ì œìŠ¤ì²˜ ì „ì†¡
            send_gesture_to_unity(stable_gesture)
            return stable_gesture

    # ì•„ì§ ì•ˆì •í™” ì‹œê°„ì´ ì§€ë‚˜ì§€ ì•Šì•˜ê±°ë‚˜ ì œìŠ¤ì²˜ê°€ Noneì¸ ê²½ìš°
    # Unityì— ì œìŠ¤ì²˜ ì—†ìŒ ì „ì†¡ (candidate_gestureê°€ Noneì¸ ê²½ìš°ë§Œ)
    if candidate_gesture is None:
        send_no_gesture_to_unity()
    return None


def classify_gesture_from_pattern(
    integrated_states, bottom_camera_state, side_camera_state
):
    """
    ì†ê°€ë½ ìƒíƒœ íŒ¨í„´ìœ¼ë¡œ ì œìŠ¤ì²˜ë¥¼ ì¦‰ì‹œ ë¶„ë¥˜í•©ë‹ˆë‹¤ (ì•ˆì •í™” ì—†ì´).

    ì œìŠ¤ì²˜ íŒ¨í„´ (Thumb, Index, Middle, Ring, Pinky):
    - A: [0, -1, -1, -1, -1]
    - Open A: [1, -1, -1, -1, -1]
    - Bent B: [1, 0, 0, 0, 0]
    - Bent V: [-1, 0, 0, -1, -1]
    - W: [-1, 1, 1, 1, -1]
    - X: [-1, 0, -1, -1, -1]
    - F: [0, 0, 1, 1, 1] + ì—„ì§€-ê²€ì§€ ë–¨ì–´ì§
    - Open F: [0, 0, 1, 1, 1] + ì—„ì§€-ê²€ì§€ ì ‘ì´‰
    - Y: [1, -1, -1, -1, 1]
    - L-I (I Love You): [1, 1, -1, -1, 1]
    - 1-1: [-1, 1, -1, -1, 1]
    - 3: [1, 1, 1, -1, -1]
    - G: [0, 1, -1, -1, -1]
    - I: [-1, -1, -1, -1, 1]
    - L: [1, 1, -1, -1, -1]
    - Bent 3: [1, 0, 0, -1, -1]
    - 8: [-1, 1, -1, 1, 1]
    - Open N: [0, 1, 1, -1, -1]
    - Open 8: [-1, 1, 0, 1, 1]
    - Bent L: [0, 0, -1, -1, -1] + ì—„ì§€-ê²€ì§€ ë–¨ì–´ì§
    - Baby O: [0, 0, -1, -1, -1] + ì—„ì§€-ê²€ì§€ ì ‘ì´‰
    - B: [-1, 1, 1, 1, 1] + ê²€ì§€-ì¤‘ì§€ ë¶™ìŒ
    - 4: [-1, 1, 1, 1, 1] + ê²€ì§€-ì¤‘ì§€ ë²Œì–´ì§
    - Open B: [1, 1, 1, 1, 1] + ê²€ì§€-ì¤‘ì§€ ë¶™ìŒ
    - 5: [1, 1, 1, 1, 1] + ê²€ì§€-ì¤‘ì§€ ë²Œì–´ì§
    - U: [-1, 1, 1, -1, -1] + ê²€ì§€-ì¤‘ì§€ ë¶™ìŒ
    - V: [-1, 1, 1, -1, -1] + ê²€ì§€-ì¤‘ì§€ ë²Œì–´ì§
    - C: [0, 0, 0, 0, 0] + ê²€ì§€-ì¤‘ì§€ ë¶™ìŒ
    - O: [0, 0, 0, 0, 0] + ì—„ì§€-ê²€ì§€ ì ‘ì´‰
    - Bent5: [0, 0, 0, 0, 0] + ê²€ì§€-ì¤‘ì§€ ë²Œì–´ì§

    Args:
        integrated_states: í†µí•© ì†ê°€ë½ ìƒíƒœ
        bottom_camera_state: í•˜ë‹¨ ì¹´ë©”ë¼ ìƒíƒœ (E/S/M/N/Tìš©)
        side_camera_state: ì¸¡ë©´ ì¹´ë©”ë¼ ìƒíƒœ (E/S/M/N/Tìš©)

    Returns:
        str: ì œìŠ¤ì²˜ ì´ë¦„ ë˜ëŠ” None
    """
    if integrated_states is None:
        return None

    bottom_states = integrated_states.get("bottom", {})

    # ì†ê°€ë½ ìƒíƒœë¥¼ ë°°ì—´ë¡œ ë³€í™˜ [Thumb, Index, Middle, Ring, Pinky]
    pattern = [
        bottom_states.get("Thumb"),
        bottom_states.get("Index"),
        bottom_states.get("Middle"),
        bottom_states.get("Ring"),
        bottom_states.get("Pinky"),
    ]

    # Noneì´ ìˆìœ¼ë©´ None ë°˜í™˜
    if None in pattern:
        return None

    # ì†ë‚  ìƒíƒœ í™•ì¸ (ê³µí†µ)
    is_side_facing = False
    if side_camera_state is not None:
        is_side_facing = getattr(side_camera_state, "is_side_facing", False)

    # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ 2-1: SG ìƒ·ê±´ ë°œì‚¬ [0, 1, 1, 1, 1]
    if pattern == [0, 1, 1, 1, 1]:
        # ì†ë‚ ì¼ ë•ŒëŠ” ì°¨ë‹¨
        if is_side_facing:
            return None
        return "SG"

    # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ 2-2: S1 ìƒ·ê±´ ì¬ì¥ì „ [-1, 1, 1, 1, 1]
    if pattern == [-1, 1, 1, 1, 1]:
        # ì†ë‚ ì¼ ë•ŒëŠ” ì°¨ë‹¨
        if is_side_facing:
            return None

        # ëª¨ë“  í´ì§„ ì†ê°€ë½(ê²€ì§€, ì¤‘ì§€, ì•½ì§€, ì†Œì§€)ì´ í•¨ê»˜ ìˆëŠ”ì§€ í™•ì¸
        extended_fingers_info = None
        if bottom_camera_state is not None:
            extended_fingers_info = getattr(
                bottom_camera_state, "extended_fingers_info", None
            )

        if extended_fingers_info is not None:
            if extended_fingers_info.get("all_together", False):
                return "S1"
            else:
                return "S1"  # ì†ê°€ë½ ë²Œì–´ì§€ë©´ ì¸ì‹í•˜ì§€ ì•ŠìŒ (4 ì œìŠ¤ì²˜)
        else:
            # ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¼ë‹¨ S1ë¡œ ì²˜ë¦¬
            return "S1"

    # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ 2-2-1: M1 ì†Œì´ ì¬ì¥ì „ [-1, 1, 1, -1, -1]
    if pattern == [-1, 1, 1, -1, -1]:
        # ì†ë‚ ì¼ ë•ŒëŠ” ì°¨ë‹¨
        if is_side_facing:
            return None
        return "M1"

    # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ 2-3: [1, 1, 1, 1, 1] íŒ¨í„´ì€ B ì œìŠ¤ì²˜ (ê¸°ë³¸ ìƒ·ê±´)
    if pattern == [1, 1, 1, 1, 1]:
        # ì†ë‚ ì¼ ë•ŒëŠ” ì°¨ë‹¨
        if is_side_facing:
            return None

        # ë„¤ ì†ê°€ë½(ê²€ì§€, ì¤‘ì§€, ì•½ì§€, ì†Œì§€)ì´ í•¨ê»˜ ìˆëŠ”ì§€ í™•ì¸ (ì—„ì§€ ì œì™¸)
        extended_fingers_info = None
        if bottom_camera_state is not None:
            extended_fingers_info = getattr(
                bottom_camera_state, "extended_fingers_info", None
            )

        if extended_fingers_info is not None:
            if extended_fingers_info.get("all_together", False):
                return "B"
            else:
                return "B"  # ì†ê°€ë½ ë²Œì–´ì§€ë©´ ì¸ì‹í•˜ì§€ ì•ŠìŒ
        else:
            return None  # ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¸ì‹í•˜ì§€ ì•ŠìŒ

    # íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ 3: [-1, 1, -1, -1, -1] íŒ¨í„´ì€ ì—„ì§€ normalized_yë¡œ 1 êµ¬ë¶„ (ë†’ì€ ìœ„ì¹˜)
    if pattern == [-1, 1, -1, -1, -1]:
        # ì†ë‚ ì¼ ë•ŒëŠ” ì°¨ë‹¨
        if is_side_facing:
            return None

        # ì—„ì§€ normalized_y í™•ì¸
        thumb_norm_y = None
        if bottom_camera_state is not None and hasattr(
            bottom_camera_state, "thumb_debug"
        ):
            thumb_norm_y = bottom_camera_state.thumb_debug.get("normalized_y", None)

        if thumb_norm_y is not None:
            if thumb_norm_y >= 0.6:  # ì—„ì§€ ë†’ìŒì¼ ë•Œë§Œ 1 ë°˜í™˜
                return "1"
            else:
                return None  # ì—„ì§€ ë‚®ìœ¼ë©´ ì¸ì‹í•˜ì§€ ì•ŠìŒ
        else:
            return None  # normalized_y ê°’ì´ ì—†ìœ¼ë©´ ì¸ì‹í•˜ì§€ ì•ŠìŒ

    # ì œìŠ¤ì²˜ íŒ¨í„´ ë§¤ì¹­ (ìˆœì„œëŒ€ë¡œ í™•ì¸)
    gesture_patterns = {
        "L": [1, 1, -1, -1, -1],
        "3": [1, 1, 1, -1, -1],
        "G": [0, 1, -1, -1, -1],
        "L-I": [1, 1, -1, -1, 1],
        "1-I": [-1, 1, -1, -1, 1],
        "8": [-1, 1, -1, 1, 1],
        "Open N": [0, 1, 1, -1, -1],
        "Bent 3": [1, 0, 0, -1, -1],
        "Baby O": [0, 0, -1, -1, -1],
    }

    # íŒ¨í„´ ë§¤ì¹­
    for gesture_name, gesture_pattern in gesture_patterns.items():
        if pattern == gesture_pattern:
            # ì†ë‚ ì¼ ë•ŒëŠ” G ì œìŠ¤ì²˜ë§Œ í—ˆìš© (HëŠ” ìœ„ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨)
            is_side_facing = False
            if side_camera_state is not None:
                is_side_facing = getattr(side_camera_state, "is_side_facing", False)

            if is_side_facing:
                # ì†ë‚ ì¼ ë•ŒëŠ” Gë§Œ í—ˆìš©
                if gesture_name == "G":
                    return gesture_name
                else:
                    return None
            else:
                # ì†Œì´ 3 ì œìŠ¤ì²˜ì— ë°œì‚¬/ì¬ì¥ì „ ë¡œì§ ì¶”ê°€
                if gesture_name == "3":
                    thumb_state = bottom_states.get("Thumb")
                    if thumb_state == 0:
                        return "3_Fire"  # ì†Œì´ ë°œì‚¬ (ì—„ì§€ Between)
                    elif thumb_state == -1:
                        return "3_Reload"  # ì†Œì´ ì¬ì¥ì „ (ì—„ì§€ Bent)
                    else:
                        return "3"  # ê¸°ë³¸ ì†Œì´ (ì—„ì§€ Straight)
                else:
                    # ë‹¤ë¥¸ ì œìŠ¤ì²˜ëŠ” ê¸°ë³¸ ì²˜ë¦¬
                    return gesture_name

    # ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ì´ ì—†ìœ¼ë©´ None ë°˜í™˜
    return None


def classify_gesture_from_integrated_states(
    integrated_states, bottom_camera_state, side_camera_state
):
    """
    í†µí•© ì†ê°€ë½ ìƒíƒœë¡œë¶€í„° ì œìŠ¤ì²˜ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤ (í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€).
    ìƒˆë¡œìš´ classify_gesture_from_pattern í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    return classify_gesture_from_pattern_stabilized(
        integrated_states, bottom_camera_state, side_camera_state
    )


def process_hand_landmarks(
    hand_landmarks, handedness, camera_state, image, other_camera_state=None
):
    """ë‹¨ì¼ ì†ì˜ ëœë“œë§ˆí¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    h, w, _ = image.shape

    # hand_landmarksì™€ ì´ë¯¸ì§€ í¬ê¸° ì €ì¥ (draw_resultsì—ì„œ ì‚¬ìš©)
    camera_state.hand_landmarks = hand_landmarks
    camera_state.image_width = w
    camera_state.image_height = h

    # ì† ë°©í–¥ í™•ì¸
    is_arm_raised = check_hand_orientation(hand_landmarks)

    # ê° ì†ê°€ë½ ê°ë„ ê³„ì‚° (MCP-PIP-TIP ë°©ì‹ìœ¼ë¡œ ë³µêµ¬)
    angles = {
        "Thumb": finger_angle(hand_landmarks, 2, 3, 4),
        "Index": finger_angle(hand_landmarks, 5, 6, 8),
        "Middle": finger_angle(hand_landmarks, 9, 10, 12),
        "Ring": finger_angle(hand_landmarks, 13, 14, 16),
        "Pinky": finger_angle(hand_landmarks, 17, 18, 20),
    }

    # í˜„ì¬ ì¹´ë©”ë¼ì˜ ê°ë„ ì €ì¥
    camera_state.finger_angles = angles.copy()

    # ===== ì‹±ê¸€ ê°ë„ë§Œ ì‚¬ìš©: ë‹¤ì¤‘ ê´€ì ˆ ê°ë„ ê³„ì‚° ì œê±° =====
    # ì‹±ê¸€ ê°ë„ë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ Multi-joint ê³„ì‚°ì€ ìƒëµ

    # ê²€ì§€ ê°ë„ ìŠ¤ë¬´ë”©
    raw_index_angle = angles["Index"]
    smoothed_index_angle = camera_state.angle_smoother.smooth(raw_index_angle)

    # ì†ë‚ (ì¸¡ë©´) ë°©í–¥ ê°ì§€ ë¨¼ì € ìˆ˜í–‰ (ì†ê°€ë½ ìƒíƒœ ë¶„ë¥˜ì—ì„œ ì‚¬ìš©)
    is_side, palm_z, confidence = check_hand_side_orientation(
        hand_landmarks, camera_state.camera_type
    )
    camera_state.is_side_facing = is_side
    camera_state.palm_normal_z = palm_z
    camera_state.side_facing_confidence = confidence

    # 3ë‹¨ê³„ ì†ê°€ë½ ìƒíƒœ ë¶„ë¥˜ (1: straight, 0: between, -1: bent)
    finger_states_numeric = {}

    for finger_name in ["Thumb", "Index", "Middle", "Ring", "Pinky"]:
        # ì—„ì§€ëŠ” íŠ¹ë³„ ì²˜ë¦¬
        if finger_name == "Thumb":
            thumb_state, thumb_normalized_y = classify_thumb_state_side(
                hand_landmarks, camera_state.camera_type, handedness
            )
            finger_states_numeric["Thumb"] = thumb_state
            thumb_extension = None
            thumb_angle_raw = finger_angle(hand_landmarks, 2, 3, 4)
            thumb_tip = hand_landmarks.landmark[4]
            index_mcp = hand_landmarks.landmark[5]
            thumb_mcp = hand_landmarks.landmark[2]

            # í•˜ë‹¨ ì¹´ë©”ë¼: normalized ì¢Œí‘œ ê¸°ë°˜ zone ë° In1/In2/In3 ê³„ì‚°
            if camera_state.camera_type == "bottom":
                wrist = hand_landmarks.landmark[0]
                middle_mcp = hand_landmarks.landmark[9]
                pinky_mcp = hand_landmarks.landmark[17]

                hand_length = math.hypot(middle_mcp.x - wrist.x, middle_mcp.y - wrist.y)
                palm_width = math.hypot(
                    index_mcp.x - pinky_mcp.x, index_mcp.y - pinky_mcp.y
                )

                palm_center_x = (wrist.x + index_mcp.x + pinky_mcp.x) / 3
                palm_center_y = (wrist.y + index_mcp.y + pinky_mcp.y) / 3

                thumb_vector_x = (thumb_tip.x - palm_center_x) / (palm_width + 1e-6)
                thumb_vector_y = (thumb_tip.y - palm_center_y) / (hand_length + 1e-6)

                if handedness == "Left":
                    thumb_vector_x = -thumb_vector_x

                normalized_x = thumb_vector_x
                normalized_y = thumb_vector_y

                THUMB_INNER_THRESHOLD = 0.54
                THUMB_OUTER_THRESHOLD = 1.4
                INNER_Y_HIGH_THRESHOLD = 0.55
                INNER_Y_LOW_THRESHOLD = 0.27

                thumb_zone = "center"
                thumb_inner_subzone = 0

                if normalized_x <= THUMB_INNER_THRESHOLD:
                    thumb_zone = "inner"
                    if normalized_y >= INNER_Y_HIGH_THRESHOLD:
                        thumb_inner_subzone = 3  # In3
                    elif normalized_y >= INNER_Y_LOW_THRESHOLD:
                        thumb_inner_subzone = 2  # In2
                    else:
                        thumb_inner_subzone = 1  # In1
                elif normalized_x >= THUMB_OUTER_THRESHOLD:
                    thumb_zone = "outer"

                thumb_extension = math.hypot(
                    thumb_tip.x - thumb_mcp.x, thumb_tip.y - thumb_mcp.y
                )
            else:
                # ì¸¡ë©´ ì¹´ë©”ë¼: ê¸°ì¡´ ë¡œì§
                thumb_zone = "outer" if thumb_tip.x > index_mcp.x else "inner"
                thumb_inner_subzone = 0  # N/A
                thumb_extension = abs(thumb_tip.x - index_mcp.x)
                normalized_x = 0
                normalized_y = 0

            debug_angle = thumb_angle_raw if thumb_zone == "inner" else -thumb_angle_raw
            thumb_extension_for_result = thumb_extension

            # ì—„ì§€ ë””ë²„ê·¸ìš© ê°’ ì €ì¥ (In1/In2/In3 ì •ë³´ í¬í•¨)
            camera_state.thumb_debug = {
                "thumb_extension": thumb_extension,
                "thumb_angle_raw": thumb_angle_raw,
                "thumb_zone": thumb_zone,
                "thumb_angle_debug": debug_angle,
                "thumb_inner_subzone": thumb_inner_subzone,
                "normalized_x": normalized_x
                if camera_state.camera_type == "bottom"
                else None,
                "normalized_y": thumb_normalized_y,
            }
            continue

        # ì—„ì§€ê°€ ì•„ë‹Œ ì†ê°€ë½ë“¤: ë‹¤ì¤‘ ê´€ì ˆ ê°ë„ ì‚¬ìš©!
        # ë‹¤ì¤‘ ê´€ì ˆ ê°ë„ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹
        # ğŸ¯ ì‹±ê¸€ ê°ë„: ì¸¡ë©´ ê°ë„ + í•˜ë‹¨ ê°ë„ë§Œ (Lower ê°ë„ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

        # ì¸¡ë©´ ì¹´ë©”ë¼ ê°ë„ (MCP-PIP-TIP)
        angle_side = angles[finger_name]

        # í•˜ë‹¨ ì¹´ë©”ë¼ ê°ë„ ê°€ì ¸ì˜¤ê¸° (ìˆìœ¼ë©´)
        angle_bottom = None
        if (
            other_camera_state is not None
            and finger_name in other_camera_state.finger_angles
        ):
            angle_bottom = other_camera_state.finger_angles[finger_name]

        # ì‹±ê¸€ ê°ë„ ë¶„ë¥˜ í•¨ìˆ˜ ì‚¬ìš© (MCP-PIP-TIPë§Œ)
        finger_states_numeric[finger_name] = classify_finger_state_single_angle(
            angle_side,  # ì¸¡ë©´ ê°ë„ (MCP-PIP-TIP)
            angle_bottom,  # í•˜ë‹¨ ê°ë„ (optional, ìœµí•©ìš©!)
            finger_name=finger_name,
            is_side_facing=camera_state.is_side_facing,
        )

    # ğŸ¯ íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ ì œê±°: ì‹±ê¸€ ê°ë„ë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ Lower ê°ë„ ì²´í¬ ì—†ìŒ

    # ë¶„ë¥˜ ê²°ê³¼ ì €ì¥
    camera_state.finger_states_numeric = finger_states_numeric

    # ì¸¡ë©´ ì¹´ë©”ë¼ì¼ ë•Œ: tip ì¢Œí‘œ ì €ì¥ (ì†ê°€ë½ ì‚¬ì´ íŒì •ìš©)
    if camera_state.camera_type == "side":
        try:
            thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]
            index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]
            middle_tip = hand_landmarks.landmark[
                mp_hands.HandLandmark.MIDDLE_FINGER_TIP
            ]
            ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]

            tx, ty = int(thumb_tip.x * w), int(thumb_tip.y * h)
            ix, iy = int(index_tip.x * w), int(index_tip.y * h)
            mx, my = int(middle_tip.x * w), int(middle_tip.y * h)
            rx, ry = int(ring_tip.x * w), int(ring_tip.y * h)

            camera_state.thumb_tip_coords = (tx, ty)
            camera_state.index_tip_coords = (ix, iy)
            camera_state.middle_tip_coords = (mx, my)
            camera_state.ring_tip_coords = (rx, ry)
        except Exception:
            camera_state.thumb_tip_coords = None
            camera_state.index_tip_coords = None
            camera_state.middle_tip_coords = None
            camera_state.ring_tip_coords = None

    # í•˜ë‹¨ì¹´ë©”ë¼ì¼ ë•Œ: tip ì¢Œí‘œ ë° ì •ê·œí™” ê´€ë ¨ ê°’ ì €ì¥ (ê±°ë¦¬ ê³„ì‚°ì€ draw_resultsì—ì„œ ìˆ˜í–‰)
    if camera_state.camera_type == "bottom":
        try:
            thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]
            index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]
            middle_tip = hand_landmarks.landmark[
                mp_hands.HandLandmark.MIDDLE_FINGER_TIP
            ]
            ring_tip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP]
            ring_dip = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_DIP]
            pinky_tip = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP]

            tx, ty = int(thumb_tip.x * w), int(thumb_tip.y * h)
            ix, iy = int(index_tip.x * w), int(index_tip.y * h)
            mx, my = int(middle_tip.x * w), int(middle_tip.y * h)
            rx, ry = int(ring_tip.x * w), int(ring_tip.y * h)
            rdx, rdy = int(ring_dip.x * w), int(ring_dip.y * h)
            px, py = int(pinky_tip.x * w), int(pinky_tip.y * h)

            camera_state.thumb_tip_coords = (tx, ty)
            camera_state.index_tip_coords = (ix, iy)
            camera_state.middle_tip_coords = (mx, my)
            camera_state.ring_tip_coords = (rx, ry)
            camera_state.ring_dip_coords = (rdx, rdy)
            camera_state.pinky_tip_coords = (px, py)

            # store 3D z-values for tip depth comparisons
            try:
                camera_state.thumb_tip_z = float(thumb_tip.z)
            except Exception:
                camera_state.thumb_tip_z = None
            try:
                camera_state.index_tip_z = float(index_tip.z)
            except Exception:
                camera_state.index_tip_z = None
            try:
                camera_state.middle_tip_z = float(middle_tip.z)
            except Exception:
                camera_state.middle_tip_z = None
            try:
                camera_state.ring_tip_z = float(ring_tip.z)
            except Exception:
                camera_state.ring_tip_z = None
            try:
                camera_state.pinky_tip_z = float(pinky_tip.z)
            except Exception:
                camera_state.pinky_tip_z = None

            # store middle finger PIP (ë‘ë²ˆì§¸ ë§ˆë””) for S gesture detection
            try:
                middle_pip = hand_landmarks.landmark[
                    mp_hands.HandLandmark.MIDDLE_FINGER_PIP
                ]
                mpx, mpy = int(middle_pip.x * w), int(middle_pip.y * h)
                camera_state.middle_pip_coords = (mpx, mpy)
                camera_state.middle_pip_z = float(middle_pip.z)
            except Exception:
                camera_state.middle_pip_coords = None
                camera_state.middle_pip_z = None

            # palm width in pixels (index MCP to pinky MCP) and hand size in 3D for normalization
            try:
                index_mcp = hand_landmarks.landmark[
                    mp_hands.HandLandmark.INDEX_FINGER_MCP
                ]
                pinky_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_MCP]
            except Exception:
                # fall back to tips if MCP not available
                index_mcp = index_tip
                pinky_mcp = ring_tip

            palm_w_px = math.hypot(
                (index_mcp.x - pinky_mcp.x) * w, (index_mcp.y - pinky_mcp.y) * h
            )
            camera_state.palm_width_pixels = palm_w_px

            # hand size (3D) for depth normalization: index_mcp to wrist
            wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]
            index_mcp_3d = hand_landmarks.landmark[
                mp_hands.HandLandmark.INDEX_FINGER_MCP
            ]
            hand_size_3d = math.sqrt(
                (index_mcp_3d.x - wrist.x) ** 2
                + (index_mcp_3d.y - wrist.y) ** 2
                + (index_mcp_3d.z - wrist.z) ** 2
            )
            camera_state.hand_size_3d = hand_size_3d

            # thumb depth (z) normalized by hand_size_3d
            try:
                thumb_z = thumb_tip.z
                thumb_depth_norm = (thumb_z - wrist.z) / (hand_size_3d + 1e-6)
                camera_state.thumb_depth_norm = thumb_depth_norm
                camera_state.thumb_tip_z = thumb_z
            except Exception:
                camera_state.thumb_depth_norm = None
                camera_state.thumb_tip_z = None

            # compute thumb relative to mean fingertip z (normalized)
            try:
                tip_zs = [
                    v
                    for v in [
                        camera_state.index_tip_z,
                        camera_state.middle_tip_z,
                        camera_state.ring_tip_z,
                    ]
                    if v is not None
                ]
                if (
                    tip_zs
                    and camera_state.thumb_tip_z is not None
                    and hand_size_3d > 1e-6
                ):
                    mean_fingertips_z = sum(tip_zs) / len(tip_zs)
                    camera_state.thumb_rel_to_fingertips_norm = (
                        camera_state.thumb_tip_z - mean_fingertips_z
                    ) / (hand_size_3d + 1e-6)
                else:
                    camera_state.thumb_rel_to_fingertips_norm = None
            except Exception:
                camera_state.thumb_rel_to_fingertips_norm = None

            # ê²€ì§€-ì¤‘ì§€ ê±°ë¦¬ ì²´í¬ (V/U êµ¬ë¶„ìš©: straightì¼ ë•Œ, C/Bent5 êµ¬ë¶„ìš©: betweenì¼ ë•Œ)
            index_state = finger_states_numeric.get("Index")
            middle_state = finger_states_numeric.get("Middle")

            # ê²€ì§€ì™€ ì¤‘ì§€ê°€ ëª¨ë‘ straight(1)ì´ê±°ë‚˜ ëª¨ë‘ between(0)ì¼ ë•Œ ê±°ë¦¬ ì²´í¬
            if (index_state == 1 and middle_state == 1) or (
                index_state == 0 and middle_state == 0
            ):
                is_together, distance, norm_dist = check_index_middle_distance(
                    camera_state, hand_size_3d
                )
                camera_state.index_middle_together = is_together
                camera_state.index_middle_distance = distance
                camera_state.index_middle_distance_norm = norm_dist
                camera_state.index_middle_norm_distance = norm_dist  # í‘œì‹œìš© alias
            else:
                camera_state.index_middle_together = None
                camera_state.index_middle_distance = None
                camera_state.index_middle_distance_norm = None
                camera_state.index_middle_norm_distance = None

            # ëª¨ë“  í´ì§„ ì†ê°€ë½ì´ í•¨ê»˜ ìˆëŠ”ì§€ ì²´í¬
            extended_fingers_info = check_extended_fingers_together(
                camera_state, finger_states_numeric, hand_size_3d
            )
            camera_state.extended_fingers_info = extended_fingers_info

            # ì—„ì§€-ë‹¤ë¥¸ì†ê°€ë½ ì ‘ì´‰ ì²´í¬ (íŠ¹ì • íŒ¨í„´ì—ì„œë§Œ)
            # íŒ¨í„´: [0,0,0,0,0], [0,0,1,1,1], [0,0,-1,-1,-1]
            pattern = [
                finger_states_numeric.get("Thumb"),
                finger_states_numeric.get("Index"),
                finger_states_numeric.get("Middle"),
                finger_states_numeric.get("Ring"),
                finger_states_numeric.get("Pinky"),
            ]

            # ì—„ì§€-ë‹¤ë¥¸ì†ê°€ë½ ì ‘ì´‰ ì²´í¬ (í•­ìƒ í™•ì¸)
            thumb_touch_info = check_thumb_touching_fingers(camera_state, hand_size_3d)
            camera_state.thumb_touch_info = thumb_touch_info

            # ğŸ¯ O vs Flattened O êµ¬ë¶„ì„ ìœ„í•œ ì¸¡ì •ê°’ ê³„ì‚° (íŒ¨í„´ [-1,0,0,0,0]ì¼ ë•Œ)
            if pattern == [-1, 0, 0, 0, 0]:
                try:
                    # 1ìœ„: Tip Clustering (4ê°œ ì†ê°€ë½ TIPì˜ ì§‘ì¤‘ë„)
                    # ê²€ì§€, ì¤‘ì§€, ì•½ì§€, ì†Œì§€ TIP ì¢Œí‘œ ìˆ˜ì§‘
                    tips_3d = []
                    if (
                        camera_state.index_tip_coords
                        and camera_state.index_tip_z is not None
                    ):
                        tips_3d.append(
                            (index_tip.x, index_tip.y, camera_state.index_tip_z)
                        )
                    if (
                        camera_state.middle_tip_coords
                        and camera_state.middle_tip_z is not None
                    ):
                        tips_3d.append(
                            (middle_tip.x, middle_tip.y, camera_state.middle_tip_z)
                        )
                    if (
                        camera_state.ring_tip_coords
                        and camera_state.ring_tip_z is not None
                    ):
                        tips_3d.append(
                            (ring_tip.x, ring_tip.y, camera_state.ring_tip_z)
                        )
                    if (
                        camera_state.pinky_tip_coords
                        and camera_state.pinky_tip_z is not None
                    ):
                        tips_3d.append(
                            (pinky_tip.x, pinky_tip.y, camera_state.pinky_tip_z)
                        )

                    if len(tips_3d) == 4:
                        # 4ê°œ TIPì˜ í‰ê·  ìœ„ì¹˜ ê³„ì‚°
                        avg_x = sum(t[0] for t in tips_3d) / 4
                        avg_y = sum(t[1] for t in tips_3d) / 4
                        avg_z = sum(t[2] for t in tips_3d) / 4

                        # ê° TIPì—ì„œ í‰ê· ê¹Œì§€ì˜ 3D ê±°ë¦¬ ê³„ì‚°
                        distances = [
                            math.sqrt(
                                (t[0] - avg_x) ** 2
                                + (t[1] - avg_y) ** 2
                                + (t[2] - avg_z) ** 2
                            )
                            for t in tips_3d
                        ]

                        # í‰ê·  ê±°ë¦¬ ê³„ì‚° (hand_size_3dë¡œ ì •ê·œí™”)
                        avg_distance = sum(distances) / 4
                        tip_clustering_norm = avg_distance / (hand_size_3d + 1e-6)
                        camera_state.tip_clustering_value = tip_clustering_norm
                    else:
                        camera_state.tip_clustering_value = None

                    # 2ìœ„: ê²€ì§€ TIP-DIP ê±°ë¦¬
                    index_dip = hand_landmarks.landmark[
                        mp_hands.HandLandmark.INDEX_FINGER_DIP
                    ]

                    # 3D ê±°ë¦¬ ê³„ì‚°
                    tip_dip_dist_3d = math.sqrt(
                        (index_tip.x - index_dip.x) ** 2
                        + (index_tip.y - index_dip.y) ** 2
                        + (index_tip.z - index_dip.z) ** 2
                    )

                    # hand_size_3dë¡œ ì •ê·œí™”
                    index_tip_dip_norm = tip_dip_dist_3d / (hand_size_3d + 1e-6)
                    camera_state.index_tip_dip_distance = index_tip_dip_norm

                except Exception as e:
                    print(f"[O/Flattened O ì¸¡ì • ì—ëŸ¬] {e}")
                    camera_state.tip_clustering_value = None
                    camera_state.index_tip_dip_distance = None
            else:
                camera_state.tip_clustering_value = None
                camera_state.index_tip_dip_distance = None

        except Exception:
            camera_state.thumb_tip_coords = None
            camera_state.index_tip_coords = None
            camera_state.middle_tip_coords = None
            camera_state.ring_tip_coords = None

    # ê±°ë¦¬ ê³„ì‚°
    index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]
    wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]

    x1_base, y1_base = int(index_mcp.x * w), int(index_mcp.y * h)
    x2_base, y2_base = int(wrist.x * w), int(wrist.y * h)
    base_dist_pixel = math.sqrt((x1_base - x2_base) ** 2 + (y1_base - y2_base) ** 2)

    norm_dist = -1.0
    raw_norm_dist = -1.0

    if base_dist_pixel > 1e-6:
        if camera_state.mode == "mode2":
            index_pip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP]
            middle_pip = hand_landmarks.landmark[
                mp_hands.HandLandmark.MIDDLE_FINGER_PIP
            ]
            x1_pip, y1_pip = int(index_pip.x * w), int(index_pip.y * h)
            x2_pip, y2_pip = int(middle_pip.x * w), int(middle_pip.y * h)
            pip_distance = math.sqrt((x1_pip - x2_pip) ** 2 + (y1_pip - y2_pip) ** 2)
            raw_norm_dist = pip_distance / base_dist_pixel
            norm_dist = camera_state.distance_smoother.smooth(raw_norm_dist)

        elif camera_state.mode == "mode1":
            index_pip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP]
            thumb_ip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP]
            x1_pip, y1_pip = int(index_pip.x * w), int(index_pip.y * h)
            x2_pip, y2_pip = int(thumb_ip.x * w), int(thumb_ip.y * h)
            pip_distance = math.sqrt((x1_pip - x2_pip) ** 2 + (y1_pip - y2_pip) ** 2)
            raw_norm_dist = pip_distance / base_dist_pixel
            norm_dist = camera_state.distance_smoother.smooth(raw_norm_dist)

    # ì†ê°€ë½ í´ì§/êµ½í˜ íŒë‹¨
    fingers = {finger: (angle > ANGLE_THRESHOLD) for finger, angle in angles.items()}
    fingers["Index"] = smoothed_index_angle > ANGLE_THRESHOLD

    # ì—„ì§€ ì²˜ë¦¬
    thumb_angle = 0
    if handedness:
        fingers["Thumb"] = is_thumb_extended(hand_landmarks, handedness)
        raw_thumb_angle = calculate_thumb_spread_angle(hand_landmarks, handedness)
        thumb_angle = camera_state.thumb_angle_smoother.smooth(raw_thumb_angle)

    # ëª¨ë“œ íŒë³„
    if not is_arm_raised:
        # mode5 ì¡°ê±´
        if (
            not fingers["Thumb"]
            and fingers["Index"]
            and fingers["Middle"]
            and fingers["Ring"]
            and fingers["Pinky"]
        ):
            camera_state.mode5_counter += 1
            if camera_state.mode5_counter >= MODE5_CONFIRM_FRAMES:
                current_mode = "mode5"
            else:
                current_mode = None
        else:
            camera_state.mode5_counter = 0

            # mode0 ì¡°ê±´
            if (
                fingers["Thumb"]
                and fingers["Index"]
                and fingers["Middle"]
                and fingers["Ring"]
                and fingers["Pinky"]
            ):
                current_mode = "mode0"

            # ê¸°ì¡´ mode1, mode2 íŒë³„ ë¡œì§
            elif camera_state.mode == "mode1":
                if (
                    fingers["Index"]
                    and fingers["Middle"]
                    and not fingers["Ring"]
                    and not fingers["Pinky"]
                ):
                    current_mode = "mode2"
                else:
                    current_mode = "mode1"
            elif camera_state.mode == "mode2":
                if (
                    fingers["Index"]
                    and not fingers["Middle"]
                    and not fingers["Ring"]
                    and not fingers["Pinky"]
                ):
                    current_mode = "mode1"
                else:
                    current_mode = "mode2"
            else:
                if (
                    fingers["Index"]
                    and fingers["Middle"]
                    and not fingers["Ring"]
                    and not fingers["Pinky"]
                ):
                    current_mode = "mode2"
                elif (
                    fingers["Index"]
                    and not fingers["Middle"]
                    and not fingers["Ring"]
                    and not fingers["Pinky"]
                ):
                    current_mode = "mode1"
                else:
                    current_mode = None

        # ëª¨ë“œ í™•ì • ì‹œìŠ¤í…œ
        if current_mode == camera_state.last_detected_mode:
            camera_state.mode_confirmation_count += 1
        else:
            camera_state.mode_confirmation_count = 1
            camera_state.last_detected_mode = current_mode

        if (
            camera_state.mode_confirmation_count >= MODE_CONFIRMATION_THRESHOLD
            and current_mode != camera_state.last_confirmed_mode
        ):
            camera_state.last_confirmed_mode = current_mode
            if current_mode:
                camera_state.mode = current_mode
                if camera_state.prev_mode != camera_state.mode:
                    camera_state.distance_smoother.reset()
                    camera_state.thumb_angle_smoother.reset()
            else:
                camera_state.mode = None
        elif camera_state.mode_confirmation_count >= MODE_CONFIRMATION_THRESHOLD:
            camera_state.mode = camera_state.last_confirmed_mode

    camera_state.prev_mode = camera_state.mode

    result_dict = {
        "fingers": fingers,
        "smoothed_index_angle": smoothed_index_angle,
        "thumb_angle": thumb_angle,
        "norm_dist": norm_dist,
        "mode": camera_state.mode,
    }
    if camera_state.camera_type == "side" and "thumb_extension_for_result" in locals():
        result_dict["thumb_extension"] = thumb_extension_for_result
    return result_dict


def draw_results(
    image,
    results,
    camera_id,
    x_offset=0,
    camera_state=None,
    integrated_states=None,
    all_camera_states=None,
):
    """ê¸°ì¡´ ë‹¨ì¼ ê°ë„ ë° ì†ê°€ë½ ìƒíƒœ í‘œì‹œ"""
    y0 = 30

    # ì¹´ë©”ë¼ ID ë° íƒ€ì… í‘œì‹œ
    camera_type_text = (
        camera_state.camera_type.upper() if camera_state is not None else ""
    )
    cv2.putText(
        image,
        f"Camera {camera_id} ({camera_type_text})",
        (x_offset + 10, y0),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.7,
        (255, 255, 255),
        2,
    )
    y0 += 40

    # ======= ì—„ì§€ í„°ì¹˜ ìƒíƒœ í‘œì‹œ =======
    if camera_state is not None and hasattr(camera_state, "thumb_touch_info"):
        thumb_touch_info = camera_state.thumb_touch_info

        # ì œëª©
        cv2.putText(
            image,
            "THUMB TOUCH STATUS",
            (x_offset + 15, y0 + 20),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (255, 255, 0),  # ë…¸ë€ìƒ‰
            2,
        )
        y0 += 30

        if thumb_touch_info is not None:
            touching = thumb_touch_info.get("touching", False)
            touched_finger = thumb_touch_info.get("touched_finger", None)
            min_distance = thumb_touch_info.get("min_distance", None)
            distances = thumb_touch_info.get("distances", {})

            # í„°ì¹˜ ìƒíƒœ í‘œì‹œ
            if touching and touched_finger:
                touch_color = (0, 255, 0)  # ë…¹ìƒ‰ (í„°ì¹˜ë¨)
                touch_text = f"TOUCHING: {touched_finger}"
            else:
                touch_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (í„°ì¹˜ ì•ˆë¨)
                touch_text = "NOT TOUCHING"

            cv2.putText(
                image,
                touch_text,
                (x_offset + 15, y0 + 20),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                touch_color,
                2,
            )
            y0 += 25

            # ìµœì†Œ ê±°ë¦¬ í‘œì‹œ
            if min_distance is not None:
                distance_color = (0, 255, 0) if touching else (255, 255, 255)
                cv2.putText(
                    image,
                    f"Min Distance: {min_distance:.1f}px (Thresh: {THUMB_TOUCH_THRESHOLD}px)",
                    (x_offset + 15, y0 + 20),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.4,
                    distance_color,
                    1,
                )
                y0 += 20

            # ê° ì†ê°€ë½ë³„ ê±°ë¦¬ í‘œì‹œ
            for finger_name in ["Index", "Middle", "Ring", "Pinky"]:
                if finger_name in distances:
                    distance = distances[finger_name]
                    is_closest = touched_finger == finger_name and touching

                    # ìƒ‰ìƒ ê²°ì •
                    if is_closest:
                        finger_color = (0, 255, 0)  # ë…¹ìƒ‰ (í„°ì¹˜ëœ ì†ê°€ë½)
                    elif distance <= THUMB_TOUCH_THRESHOLD:
                        finger_color = (0, 255, 255)  # ë…¸ë€ìƒ‰ (ì„ê³„ê°’ ë‚´)
                    else:
                        finger_color = (200, 200, 200)  # íšŒìƒ‰

                    cv2.putText(
                        image,
                        f"  {finger_name}: {distance:.1f}px",
                        (x_offset + 15, y0 + 20),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.4,
                        finger_color,
                        1,
                    )
                    y0 += 18
        else:
            # thumb_touch_infoê°€ Noneì¸ ê²½ìš°
            cv2.putText(
                image,
                "No touch data available",
                (x_offset + 15, y0 + 20),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.4,
                (128, 128, 128),
                1,
            )
            y0 += 25

        y0 += 15

    # ======= í†µí•© ì œìŠ¤ì²˜ í‘œì‹œ (ìƒë‹¨ ì¹´ë©”ë¼ë§Œ) =======
    if camera_id == 0 and integrated_states is not None:
        y0 += 10
        h, w = image.shape[:2]
        y_base = h - 100
        x_base = w - 250

        cv2.rectangle(
            image, (x_base - 10, y_base - 10), (w - 10, h - 10), (40, 40, 40), -1
        )
        cv2.putText(
            image,
            "[Final Integrated States]",
            (x_base, y_base),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (255, 255, 0),
            2,
        )
        y = y_base + 25

        # Bent5 ì œìŠ¤ì²˜ ê°ì§€ í™•ì¸ (í•˜ë‹¨ ì¹´ë©”ë¼ ìƒíƒœ í™•ì¸)
        is_bent5 = False
        if all_camera_states and len(all_camera_states) > 1:
            bottom_camera_state = all_camera_states[1]
            four_fingers_lower_bent = getattr(
                bottom_camera_state, "four_fingers_lower_bent", False
            )
            if four_fingers_lower_bent:
                is_bent5 = True

        for finger in ["Thumb", "Index", "Middle", "Ring", "Pinky"]:
            bottom_val = integrated_states.get("bottom", {}).get(finger, None)
            side_val = integrated_states.get("side", {}).get(finger, None)

            # Bent5ì¼ ë•Œ 4ì†ê°€ë½ ê°•ì œë¡œ -1
            if is_bent5 and finger in ["Index", "Middle", "Ring", "Pinky"]:
                final_val = -1
            # ì¼ë°˜ ìœµí•© ë¡œì§
            elif bottom_val == -1 or side_val == -1:
                final_val = -1
            elif bottom_val == 1 and side_val == 1:
                final_val = 1
            else:
                final_val = 0

            # ë””ë²„ê·¸: 4ì†ê°€ë½ ìƒíƒœ ì¶œë ¥
            if finger in ["Index", "Middle", "Ring", "Pinky"]:
                bent5_mark = " [Bent5 ê°•ì œ]" if is_bent5 else ""
                print(
                    f"[í†µí•©] {finger}: bottom={bottom_val}, side={side_val} â†’ final={final_val}{bent5_mark}"
                )

            txt = f"{finger}: {final_val:+d}"
            cv2.putText(
                image,
                txt,
                (x_base + 10, y),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (0, 255, 255),
                1,
            )
            y += 18

    # í•˜ë‹¨ ì¹´ë©”ë¼ì¼ ê²½ìš°: ì œìŠ¤ì²˜ ë¶„ë¥˜ ë° í‘œì‹œ
    bottom_camera_state = None
    side_camera_state = None

    if camera_id == 1 and all_camera_states:  # í•˜ë‹¨ ì¹´ë©”ë¼
        bottom_camera_state = (
            all_camera_states[1] if len(all_camera_states) > 1 else None
        )
        side_camera_state = all_camera_states[0] if len(all_camera_states) > 0 else None

    if (
        camera_id == 1
        and camera_state is not None
        and camera_state.camera_type == "bottom"
        and integrated_states is not None
    ):
        gesture = classify_gesture_from_integrated_states(
            integrated_states, bottom_camera_state, side_camera_state
        )

        # ì œìŠ¤ì²˜ í‘œì‹œ (í° ê¸€ì”¨, ëˆˆì— ë„ëŠ” ìƒ‰ìƒ)
        if gesture:
            gesture_color_map = {
                # E/S/M/N/T/C (ëª¨ë“  ì†ê°€ë½ bent ì œìŠ¤ì²˜)
                "C": (0, 255, 255),  # ë…¸ë‘ (ì†ë‚  ë°©í–¥) - ìµœìš°ì„ !
                "T": (255, 255, 255),  # í°ìƒ‰ (ìƒë‹¨: ê²€ì§€-ì¤‘ì§€ ì‚¬ì´)
                "N": (255, 255, 0),  # ì‹œì•ˆ (ìƒë‹¨: ì¤‘ì§€-ì•½ì§€ ì‚¬ì´)
                "M": (0, 165, 255),  # ì£¼í™©ìƒ‰ (ìƒë‹¨: ì•½ì§€-ì†Œì§€ ì‚¬ì´)
                "E": (0, 255, 0),  # ì´ˆë¡ìƒ‰ (í•˜ë‹¨ Y: 0.3~0.5)
                "S": (255, 0, 255),  # ë§ˆì  íƒ€ (í•˜ë‹¨ Y: 0.64~0.8)
                "Bent5": (255, 100, 255),  # ë°ì€ ë§ˆì  íƒ€ (4ì†ê°€ë½ Lower bent)
                # íŒ¨í„´ ê¸°ë°˜ ì œìŠ¤ì²˜
                "A": (100, 200, 255),  # ì—°í•œ ì£¼í™©ìƒ‰
                "Open A": (0, 200, 255),  # ì§„í•œ ì£¼í™©ìƒ‰
                "Bent V": (200, 150, 100),  # ê°ˆìƒ‰
                "W": (255, 200, 100),  # ê³¨ë“œ
                "X": (150, 100, 200),  # ë³´ë¼ìƒ‰
                "F": (100, 255, 100),  # ì—°í•œ ì´ˆë¡
                "Open F": (0, 200, 100),  # ì§„í•œ ì´ˆë¡
                "Y": (255, 100, 200),  # í•‘í¬
                "L-I": (200, 100, 255),  # ì—°ë³´ë¼
                "1-1": (100, 255, 255),  # ì—°í•œ ì‹œì•ˆ
                "3": (255, 150, 0),  # ì˜¤ë Œì§€
                "G": (150, 200, 255),  # í•˜ëŠ˜ìƒ‰
                "I": (200, 200, 100),  # í™©ë¡ìƒ‰
                "L": (255, 180, 180),  # ì—°ë¶„í™
                "Bent 3": (180, 100, 150),  # ìì£¼ìƒ‰
                "8": (100, 180, 255),  # ë°ì€ íŒŒë‘
                "Open N": (150, 255, 150),  # ì—°ë‘ìƒ‰
                "Open 8": (255, 150, 150),  # ì—°ë¹¨ê°•
                "Bent L": (200, 255, 100),  # ì—°ë‘-ë…¸ë‘
                "Baby O": (255, 200, 200),  # ì—°í•œ í•‘í¬
                "B": (80, 127, 255),  # ì£¼í™©-ì½”ë„
                "4": (255, 191, 0),  # ë”¥ ìŠ¤ì¹´ì´ë¸”ë£¨
                # ë¬´ê¸° ì œìŠ¤ì²˜ ìƒ‰ìƒ
                "3_Fire": (255, 0, 0),  # ë¹¨ê°• (ì†Œì´ ë°œì‚¬)
                "3_Reload": (255, 255, 0),  # ë…¸ë‘ (ì†Œì´ ì¬ì¥ì „)
                "SG": (255, 0, 200),  # ë°ì€ ë§ˆì  íƒ€ (ìƒ·ê±´ ë°œì‚¬)
                "S1": (255, 150, 0),  # ë°ì€ ì£¼í™© (ìƒ·ê±´ ì¬ì¥ì „)
                "M1": (200, 255, 0),  # ì—°ë‘-ë…¸ë‘ (ì†Œì´ ì¬ì¥ì „2)
                "Open B": (147, 20, 255),  # ë”¥ í•‘í¬
                "5": (0, 255, 255),  # ì˜ë¡œìš°
                "U": (180, 105, 255),  # í•« í•‘í¬
                "V": (203, 192, 255),  # ë¡œì¦ˆ ë¸Œë¼ìš´
                "K": (50, 200, 50),  # K: ë…¹ìƒ‰ ê³„ì—´
                "R": (0, 120, 255),  # R: ì£¼í™©-íŒŒë‘ ê³„ì—´
                "1": (255, 255, 100),  # 1: ë°ì€ ë…¸ë‘
                "D": (100, 100, 255),  # D: ë°ì€ íŒŒë‘
                "O": (255, 128, 0),  # O: ì£¼í™©ìƒ‰
                "Flattened O": (0, 128, 255),  # Flattened O: ë°ì€ ì£¼í™©ìƒ‰
            }
            gesture_color = gesture_color_map.get(gesture, (200, 200, 200))
            cv2.putText(
                image,
                f"GESTURE: {gesture}",
                (x_offset + 10, y0),
                cv2.FONT_HERSHEY_SIMPLEX,
                1.0,  # í° ê¸€ì”¨
                gesture_color,
                3,
            )
            y0 += 40

    # ì†ê°€ë½ ë¶™ìŒ/í´ì§ ìƒíƒœ í‘œì‹œ (ì—„ì§€ ì œì™¸)
    if camera_state is not None and hasattr(camera_state, "extended_fingers_info"):
        extended_info = camera_state.extended_fingers_info
        if extended_info:
            # í´ì§„ ì†ê°€ë½ ë¦¬ìŠ¤íŠ¸ (ì—„ì§€ ì œì™¸: Index, Middle, Ring, Pinkyë§Œ)
            extended_fingers = extended_info.get("extended_fingers", [])
            all_together = extended_info.get("all_together", False)

            if extended_fingers:
                fingers_text = ", ".join(extended_fingers)
                status_text = "TOGETHER" if all_together else "SEPARATED"
                status_color = (
                    (0, 255, 0) if all_together else (0, 0, 255)
                )  # ì´ˆë¡ìƒ‰: ë¶™ìŒ, ë¹¨ê°•ìƒ‰: í´ì§

                cv2.putText(
                    image,
                    f"Fingers (no Thumb): {fingers_text}",
                    (x_offset + 10, y0),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (255, 255, 255),
                    2,
                )
                y0 += 30

                cv2.putText(
                    image,
                    f"Status: {status_text}",
                    (x_offset + 10, y0),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.7,
                    status_color,
                    2,
                )
                y0 += 35

                # ê° ìŒì˜ ê±°ë¦¬ í‘œì‹œ (ë””ë²„ê¹…ìš©)
                pairwise_distances = extended_info.get("pairwise_distances", {})
                if pairwise_distances:
                    for pair, distance in pairwise_distances.items():
                        # Ring-PinkyëŠ” íŠ¹ë³„ í‘œì‹œ
                        if pair == "Ring-Pinky":
                            pair_text = f"{pair} (Ring DIP-Pinky TIP): {distance:.1f}px"
                        else:
                            pair_text = f"{pair} (TIP-TIP): {distance:.1f}px"

                        cv2.putText(
                            image,
                            pair_text,
                            (x_offset + 10, y0),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.5,
                            (200, 200, 200),
                            1,
                        )
                        y0 += 20

    # ì—„ì§€ ì ‘ì´‰ ì •ë³´ í‘œì‹œ
    if camera_state is not None and hasattr(camera_state, "thumb_touch_info"):
        thumb_touch_info = camera_state.thumb_touch_info
        if thumb_touch_info:
            is_touching = thumb_touch_info.get("touching", False)
            touched_finger = thumb_touch_info.get("touched_finger", None)
            min_distance = thumb_touch_info.get("min_distance", None)

            if is_touching and touched_finger:
                cv2.putText(
                    image,
                    f"Thumb Touch: {touched_finger}",
                    (x_offset + 10, y0),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.7,
                    (0, 255, 255),  # ë…¸ë€ìƒ‰
                    2,
                )
                y0 += 30

                if min_distance is not None:
                    cv2.putText(
                        image,
                        f"Distance: {min_distance:.1f}px",
                        (x_offset + 10, y0),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.5,
                        (200, 200, 200),
                        1,
                    )
                    y0 += 25
            else:
                cv2.putText(
                    image,
                    "Thumb Touch: None",
                    (x_offset + 10, y0),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (150, 150, 150),  # íšŒìƒ‰
                    1,
                )
                y0 += 30

    # ì¸¡ë©´ ì¹´ë©”ë¼: ì—„ì§€ê°€ ì†ê°€ë½ ì‚¬ì´ì— ë¼ì–´ìˆëŠ”ì§€ í•­ìƒ í‘œì‹œ
    if camera_state is not None and camera_state.camera_type == "side":
        # ì €ì¥ëœ hand_landmarksì™€ ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
        hand_landmarks = getattr(camera_state, "hand_landmarks", None)
        img_w = getattr(camera_state, "image_width", None)
        img_h = getattr(camera_state, "image_height", None)

        if hand_landmarks and img_w and img_h:
            # ì†ê°€ë½ ì‚¬ì´ íŒì • (PIP ê¸°ë°˜)
            is_between, segment, details = check_thumb_between_fingers_side(
                camera_state, hand_landmarks, img_w, img_h
            )

            # ê²°ê³¼ í‘œì‹œ
            if is_between:
                if segment == "IM":
                    result_text = "Thumb: Index-Middle (T)"
                    result_color = (255, 255, 255)  # í°ìƒ‰
                elif segment == "MR":
                    result_text = "Thumb: Middle-Ring (N)"
                    result_color = (255, 255, 0)  # ì‹œì•ˆ
                elif segment == "RP":
                    result_text = "Thumb: Ring-Pinky (M)"
                    result_color = (0, 165, 255)  # ì£¼í™©
                else:
                    result_text = f"Thumb: {segment}"
                    result_color = (0, 255, 0)  # ì´ˆë¡ìƒ‰
            else:
                result_text = "Thumb: NOT BETWEEN"
                result_color = (100, 100, 100)  # íšŒìƒ‰

            cv2.putText(
                image,
                result_text,
                (x_offset + 10, y0),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.8,
                result_color,
                2,
            )
            y0 += 30

            # ìƒì„¸ ê°’ í‘œì‹œ (ë¹¨ê°„ìƒ‰)
            cv2.putText(
                image,
                "==== Between Fingers Details ====",
                (x_offset + 10, y0),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 0, 255),
                2,
            )
            y0 += 25

            # Thumb Y ìœ„ì¹˜
            ty = details.get("ty")
            if ty is not None:
                cv2.putText(
                    image,
                    f"Thumb Y: {ty}",
                    (x_offset + 10, y0),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (0, 0, 255),
                    2,
                )
                y0 += 22

            # X ë²”ìœ„ ì²´í¬ (OUT_OF_X_RANGEì¸ ê²½ìš°)
            if segment == "OUT_OF_X_RANGE":
                tx = details.get("tx")
                x_range = details.get("x_range")
                margin = details.get("margin", 40)
                if tx is not None and x_range is not None:
                    cv2.putText(
                        image,
                        f"X: {tx} (range: {x_range[0]}-{x_range[1]} +/-{margin})",
                        (x_offset + 10, y0),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (0, 0, 255),
                        2,
                    )
                    y0 += 22

            # ì„¸ê·¸ë¨¼íŠ¸ë³„ ë²”ìœ„ ì •ë³´ (NONEì¸ ê²½ìš°)
            if segment == "NONE":
                im_range = details.get("im_range")
                mr_range = details.get("mr_range")
                rp_range = details.get("rp_range")

                if im_range:
                    cv2.putText(
                        image,
                        f"IM(T) range: {im_range[0]:.1f} - {im_range[1]:.1f}",
                        (x_offset + 10, y0),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (0, 0, 255),
                        2,
                    )
                    y0 += 22

                if mr_range:
                    cv2.putText(
                        image,
                        f"MR(N) range: {mr_range[0]:.1f} - {mr_range[1]:.1f}",
                        (x_offset + 10, y0),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (0, 0, 255),
                        2,
                    )
                    y0 += 22

                if rp_range:
                    cv2.putText(
                        image,
                        f"RP(M) range: {rp_range[0]:.1f} - {rp_range[1]:.1f}",
                        (x_offset + 10, y0),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (0, 0, 255),
                        2,
                    )
                    y0 += 22

            # ë§¤ì¹­ëœ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ (IM, MR, RPì¸ ê²½ìš°)
            if is_between:
                seg_range = details.get("segment_y_range")
                seg_center = details.get("segment_y_center")
                dist_from_center = details.get("distance_from_center")
                confidence = details.get("confidence")

                if seg_range:
                    cv2.putText(
                        image,
                        f"Segment Y range: {seg_range[0]} - {seg_range[1]}",
                        (x_offset + 10, y0),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (0, 0, 255),
                        2,
                    )
                    y0 += 22

                if seg_center is not None:
                    cv2.putText(
                        image,
                        f"Segment center: {seg_center:.1f}",
                        (x_offset + 10, y0),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (0, 0, 255),
                        2,
                    )
                    y0 += 22

                if dist_from_center is not None:
                    cv2.putText(
                        image,
                        f"Distance from center: {dist_from_center:.1f}",
                        (x_offset + 10, y0),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (0, 0, 255),
                        2,
                    )
                    y0 += 22

                if confidence is not None:
                    cv2.putText(
                        image,
                        f"Confidence: {confidence:.2f}",
                        (x_offset + 10, y0),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        (0, 255, 0) if confidence > 0.7 else (0, 0, 255),
                        2,
                    )
                    y0 += 22

            # ì„ê³„ê°’ ì •ë³´ í‘œì‹œ
            cv2.putText(
                image,
                "Thresholds: X_margin=40px, Y_margin=30%",
                (x_offset + 10, y0),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 0, 255),
                2,
            )
            y0 += 25

        # --- ë””ë²„ê·¸: ì†ë‚ ì¼ ë•Œ ì¸¡ë©´ ì¹´ë©”ë¼ ì¶”ì ê°’ í‘œì‹œ (ìˆ¨ê¹€ ì²˜ë¦¬) ---
        # í•„ìš”ì‹œ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ë””ë²„ê·¸ ê°€ëŠ¥
        # try:
        #     # ì†ë‚  ìƒíƒœ í™•ì¸
        #     is_side_facing = getattr(camera_state, "is_side_facing", False)
        #
        #     if is_side_facing:
        #         debug_x = x_offset + 10
        #         # í—¤ë” (ë¹¨ê°„ìƒ‰)
        #         cv2.putText(
        #             image,
        #             "==== SIDE FACING: Finger Tracking Values ====",
        #             (debug_x, y0),
        #             cv2.FONT_HERSHEY_SIMPLEX,
        #             0.6,
        #             (0, 0, 255),
        #             2,
        #         )
        #         y0 += 25
        #
        #         # ë‹¤ë¥¸ ì¹´ë©”ë¼ ìƒíƒœ(ê°€ëŠ¥í•˜ë©´ í•˜ë‹¨)
        #         other_state = None
        #         if all_camera_states and len(all_camera_states) > 1:
        #             other_state = all_camera_states[1]
        #
        #         for finger in ["Thumb", "Index", "Middle", "Ring", "Pinky"]:
        #             side_ang = None
        #             other_ang = None
        #             state_val = None
        #             if hasattr(camera_state, "finger_angles") and camera_state.finger_angles:
        #                 side_ang = camera_state.finger_angles.get(finger)
        #             if other_state is not None and hasattr(other_state, "finger_angles") and other_state.finger_angles:
        #                 other_ang = other_state.finger_angles.get(finger)
        #             if hasattr(camera_state, "finger_states_numeric") and camera_state.finger_states_numeric:
        #                 state_val = camera_state.finger_states_numeric.get(finger)
        #
        #             # í¬ë§· í…ìŠ¤íŠ¸
        #             side_txt = f"{side_ang:.1f}" if side_ang is not None else "N/A"
        #             other_txt = f"{other_ang:.1f}" if other_ang is not None else "N/A"
        #             state_txt = f"{state_val:+d}" if isinstance(state_val, int) else str(state_val)
        #
        #             # ê° ì†ê°€ë½ë³„ ì •ë³´ (ë¹¨ê°„ìƒ‰, ë” ë‘ê»ê²Œ)
        #             cv2.putText(
        #                 image,
        #                 f"{finger}: side={side_txt} other={other_txt} state={state_txt}",
        #                 (debug_x, y0),
        #                 cv2.FONT_HERSHEY_SIMPLEX,
        #                 0.6,
        #                 (0, 0, 255),
        #                 2,
        #             )
        #             y0 += 22
        #
        #         # ì—„ì§€ ì„¸ë¶€ê°’(ê°€ëŠ¥í•˜ë©´) - ë¹¨ê°„ìƒ‰
        #         thumb_dbg = getattr(camera_state, "thumb_debug", None)
        #         if thumb_dbg:
        #             tx = thumb_dbg.get("thumb_extension")
        #             tz = thumb_dbg.get("thumb_angle_debug")
        #             tzone = thumb_dbg.get("thumb_zone")
        #             nx = thumb_dbg.get("normalized_x")
        #             ny = thumb_dbg.get("normalized_y")
        #
        #             nx_str = f"{nx:.3f}" if nx is not None else "N/A"
        #             ny_str = f"{ny:.3f}" if ny is not None else "N/A"
        #             tx_str = f"{tx:.3f}" if tx is not None else "N/A"
        #             tz_str = f"{tz:.1f}" if tz is not None else "N/A"
        #
        #             cv2.putText(
        #                 image,
        #                 f"Thumb: ext={tx_str} ang={tz_str} zone={tzone}",
        #                 (debug_x, y0),
        #                 cv2.FONT_HERSHEY_SIMPLEX,
        #                 0.6,
        #                 (0, 0, 255),
        #                 2,
        #             )
        #             y0 += 22
        #             cv2.putText(
        #                 image,
        #                 f"Thumb: nx={nx_str} ny={ny_str}",
        #                 (debug_x, y0),
        #                 cv2.FONT_HERSHEY_SIMPLEX,
        #                 0.6,
        #                 (0, 0, 255),
        #                 2,
        #             )
        #             y0 += 25
        # except Exception:
        #     pass

        # ê±°ë¦¬
        norm_dist = results["norm_dist"]
        if norm_dist > 0:
            cv2.putText(
                image,
                f"Distance: {norm_dist:.3f}",
                (x_offset + 10, y0),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 0, 255),
                2,
            )
        else:
            cv2.putText(
                image,
                "Distance: N/A",
                (x_offset + 10, y0),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 0, 255),
                2,
            )
    y0 += 25


def main():
    global INDEX_MIDDLE_DISTANCE_THRESHOLD, THUMB_TOUCH_THRESHOLD

    # Unity ì›¹ì†Œì¼“ ì—°ê²° ì´ˆê¸°í™”
    print("Unity ì›¹ì†Œì¼“ ì—°ê²° ì‹œë„...")
    init_unity_websocket()

    # ì¹´ë©”ë¼ ìƒíƒœ ì´ˆê¸°í™” (0: side/ì¸¡ë©´, 1: bottom/í•˜ë‹¨)
    camera_states = {
        0: CameraState(0, camera_type="side"),
        1: CameraState(1, camera_type="bottom"),
    }

    # ì¹´ë©”ë¼ ì—´ê¸° (ë©€í‹°ìŠ¤ë ˆë”© ë²„ì „ ì‚¬ìš©)
    print("Starting threaded cameras...")
    cap0 = ThreadedCamera(0).start()
    cap1 = ThreadedCamera(1).start()

    # ì¹´ë©”ë¼ ì´ˆê¸°í™” ëŒ€ê¸°
    time.sleep(0.5)

    print("Threaded cameras ready")

    # ì›¹ì†Œì¼“ ì—°ê²°
    ws = None
    try:
        ws = websocket.create_connection("ws://192.168.0.210:5678", timeout=2)
        print("WebSocket connected.")
    except Exception as e:
        print(f"WebSocket connection failed: {e}")
        print("Continuing without WebSocket connection...")
        ws = None

    # ê° ì¹´ë©”ë¼ë³„ë¡œ ë…ë¦½ì ì¸ MediaPipe Hands ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    # ìµœì í™”: model_complexity=0 (ê°€ì¥ ë¹ ë¥¸ ëª¨ë¸)
    hands_side = mp_hands.Hands(
        max_num_hands=1,
        model_complexity=0,  # 0=ê°€ì¥ ë¹ ë¦„, 1=ê¸°ë³¸ê°’
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5,
    )
    hands_bottom = mp_hands.Hands(
        max_num_hands=1,
        model_complexity=0,  # 0=ê°€ì¥ ë¹ ë¦„, 1=ê¸°ë³¸ê°’
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5,
    )

    # FPS ê³„ì‚°ì„ ìœ„í•œ ë³€ìˆ˜
    frame_count = 0
    fps_start_time = time.time()
    fps = 0

    # ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ëˆ„ì  ë³€ìˆ˜
    total_read_time = 0
    total_resize_time = 0
    total_mediapipe_time = 0
    total_draw_time = 0
    total_loop_time = 0

    try:
        while True:
            loop_start = time.time()

            # ë‘ ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ ì½ê¸° (ì´ë¯¸ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì½ê³  ìˆìŒ)
            t0 = time.time()
            ret0, frame0 = cap0.read()
            ret1, frame1 = cap1.read()
            read_time = time.time() - t0

            if not ret0 or not ret1 or frame0 is None or frame1 is None:
                print("ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue  # break ëŒ€ì‹  continueë¡œ ë³€ê²½

            # í”„ë ˆì„ í¬ê¸° ì¡°ì • (ë” ì‘ê²Œ í•´ì„œ ì²˜ë¦¬ ì†ë„ í–¥ìƒ)
            t0 = time.time()
            frame0 = cv2.resize(frame0, (480, 360))  # 640x480 â†’ 480x360
            frame1 = cv2.resize(frame1, (480, 360))
            resize_time = time.time() - t0

            # ê° ì¹´ë©”ë¼ë³„ë¡œ ì† ì¶”ì  ì²˜ë¦¬
            results_data = {}
            processed_frames = [None, None]

            # 1ë‹¨ê³„: ëª¨ë“  ì¹´ë©”ë¼ì—ì„œ ëœë“œë§ˆí¬ ì¶”ì  ì‹œì‘
            t0 = time.time()

            # 1ë‹¨ê³„: ëª¨ë“  ì¹´ë©”ë¼ì—ì„œ ëœë“œë§ˆí¬ ì¶”ì¶œ ë° ê°ë„ ê³„ì‚°
            for camera_id, (frame, camera_state) in enumerate(
                [(frame0, camera_states[0]), (frame1, camera_states[1])]
            ):
                # ì¹´ë©”ë¼ë³„ë¡œ ì ì ˆí•œ hands ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ
                hands = hands_side if camera_id == 0 else hands_bottom

                # ì´ë¯¸ì§€ ì²˜ë¦¬
                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                image.flags.writeable = False
                results = hands.process(image)

                # ê²°ê³¼ ë‹¤ì‹œ BGRë¡œ
                image.flags.writeable = True
                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

                # ëœë“œë§ˆí¬ ì²˜ë¦¬
                if results.multi_hand_landmarks:
                    for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
                        handedness = None
                        if results.multi_handedness:
                            handedness = (
                                results.multi_handedness[idx].classification[0].label
                            )

                        # ë‹¤ë¥¸ ì¹´ë©”ë¼ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
                        other_camera_id = 1 - camera_id
                        other_camera_state = camera_states[other_camera_id]

                        # ì† ëœë“œë§ˆí¬ ì²˜ë¦¬ (ë‹¤ë¥¸ ì¹´ë©”ë¼ ì •ë³´ ì „ë‹¬)
                        hand_results = process_hand_landmarks(
                            hand_landmarks,
                            handedness,
                            camera_state,
                            image,
                            other_camera_state,
                        )
                        results_data[camera_id] = hand_results

                        # ê²°ê³¼ ê·¸ë¦¬ê¸° (camera_state ì „ë‹¬)
                        # í•˜ë‹¨ì¹´ë©”ë¼(1ë²ˆ)ì¼ ë•Œ í†µí•© ê²°ê³¼ ì „ë‹¬
                        integrated_states = None
                        if camera_id == 1:
                            integrated_states = {
                                "side": camera_states[0].finger_states_numeric.copy()
                                if camera_states[0].finger_states_numeric
                                else None,
                                "bottom": camera_states[1].finger_states_numeric.copy()
                                if camera_states[1].finger_states_numeric
                                else None,
                            }
                        draw_results(
                            image,
                            hand_results,
                            camera_id,
                            camera_state=camera_state,
                            integrated_states=integrated_states,
                            all_camera_states=camera_states,
                        )

                        # ì† ëœë“œë§ˆí¬ ì‹œê°í™”
                        mp_drawing.draw_landmarks(
                            image, hand_landmarks, mp_hands.HAND_CONNECTIONS
                        )

                        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìˆ˜ì§‘
                        if (
                            camera_state.calibration.state
                            in ["mode1_collect", "mode2_collect"]
                            and hand_results["mode"]
                            and hand_results["norm_dist"] > 0
                        ):
                            camera_state.calibration.collect_sample(
                                hand_results["mode"], hand_results["norm_dist"]
                            )

                processed_frames[camera_id] = image

            mediapipe_time = time.time() - t0

            # ë‘ í”„ë ˆì„ì„ ë‚˜ë€íˆ í•©ì¹˜ê¸°
            t0 = time.time()
            processed_frame0 = (
                processed_frames[0] if processed_frames[0] is not None else frame0
            )
            processed_frame1 = (
                processed_frames[1] if processed_frames[1] is not None else frame1
            )

            # ì¸¡ë©´ì¹´ë©”ë¼(0ë²ˆ) ìš°ì¸¡í•˜ë‹¨ì— ìµœì¢… í†µí•©ê°’ë§Œ í‘œì‹œ
            if processed_frames[0] is not None:
                h, w = processed_frame0.shape[:2]
                y_base = h - 160
                x_base = w - 180
                cv2.rectangle(
                    processed_frame0,
                    (x_base - 10, y_base - 10),
                    (w - 10, h - 10),
                    (40, 40, 40),
                    -1,
                )
                cv2.putText(
                    processed_frame0,
                    "[Finger States]",
                    (x_base, y_base),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (255, 255, 0),
                    2,
                )
                y = y_base + 30
                # í†µí•©ê°’: Thumbì€ í•˜ë‹¨ì¹´ë©”ë¼, ë‚˜ë¨¸ì§€ëŠ” ì¸¡ë©´ì¹´ë©”ë¼ ê¸°ì¤€
                thumb_bottom = camera_states[1].finger_states_numeric.get("Thumb", None)
                fingers_side = camera_states[0].finger_states_numeric
                for idx, finger in enumerate(
                    ["Thumb", "Index", "Middle", "Ring", "Pinky"]
                ):
                    if finger == "Thumb":
                        val = thumb_bottom
                    else:
                        val = fingers_side.get(finger, None)
                    if val is not None:
                        txt = f"{finger}: {val:+d}"
                        cv2.putText(
                            processed_frame0,
                            txt,
                            (x_base + 10, y + idx * 24),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.65,
                            (0, 255, 255),
                            2,
                        )

            combined_frame = np.hstack((processed_frame0, processed_frame1))
            draw_time = time.time() - t0

            # í™”ë©´ì— í‘œì‹œ
            t0 = time.time()
            cv2.imshow("Dual Camera Hand Tracking", combined_frame)
            display_time = time.time() - t0

            # ì „ì²´ ë£¨í”„ ì‹œê°„
            loop_time = time.time() - loop_start

            # ì‹œê°„ ëˆ„ì 
            total_read_time += read_time
            total_resize_time += resize_time
            total_mediapipe_time += mediapipe_time
            total_draw_time += draw_time
            total_loop_time += loop_time

            # FPS ê³„ì‚° ë° ì¶œë ¥
            frame_count += 1
            elapsed_time = time.time() - fps_start_time
            if elapsed_time >= 0.1:  # 1ì´ˆë§ˆë‹¤ FPS ì¶œë ¥
                fps = frame_count / elapsed_time
                print(f"FPS: {fps:.2f}")

                frame_count = 0
                fps_start_time = time.time()
                total_read_time = 0
                total_resize_time = 0
                total_mediapipe_time = 0
                total_draw_time = 0
                total_loop_time = 0

            # í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF

            if key == ord("q") or key == 27:  # 'q' ë˜ëŠ” ESC
                break
            elif key == ord("1"):  # Mode1 ìº˜ë¦¬ë¸Œë ˆì´ì…˜
                for camera_state in camera_states.values():
                    camera_state.calibration.start_mode1_calibration()
                print("Mode1 calibration started for both cameras")
            elif key == ord("2"):  # Mode2 ìº˜ë¦¬ë¸Œë ˆì´ì…˜
                for camera_state in camera_states.values():
                    camera_state.calibration.start_mode2_calibration()
                print("Mode2 calibration started for both cameras")
            elif key == ord("0"):  # ì›¹ì†Œì¼“ ì¬ì—°ê²°
                if ws is None:
                    try:
                        ws = websocket.create_connection(
                            "ws://192.168.0.210:5678", timeout=2
                        )
                        print("WebSocket reconnected.")
                    except Exception as e:
                        print(f"WebSocket reconnection failed: {e}")
                        ws = None
                else:
                    print("WebSocket is already connected.")
            elif key == ord("+") or key == ord("="):  # ì„ê³„ê°’ ì¦ê°€
                INDEX_MIDDLE_DISTANCE_THRESHOLD += 0.01
                print(
                    f"Index-Middle threshold increased to {INDEX_MIDDLE_DISTANCE_THRESHOLD:.4f}"
                )
            elif key == ord("-") or key == ord("_"):  # ì„ê³„ê°’ ê°ì†Œ
                INDEX_MIDDLE_DISTANCE_THRESHOLD = max(
                    0.01, INDEX_MIDDLE_DISTANCE_THRESHOLD - 0.01
                )
                print(
                    f"Index-Middle threshold decreased to {INDEX_MIDDLE_DISTANCE_THRESHOLD:.4f}"
                )
            elif key == ord("t"):  # ì—„ì§€ ì ‘ì´‰ ì„ê³„ê°’ ê°ì†Œ
                THUMB_TOUCH_THRESHOLD = max(0.01, THUMB_TOUCH_THRESHOLD - 0.01)
                print(f"Thumb touch threshold decreased to {THUMB_TOUCH_THRESHOLD:.4f}")
            elif key == ord("T"):  # ì—„ì§€ ì ‘ì´‰ ì„ê³„ê°’ ì¦ê°€
                THUMB_TOUCH_THRESHOLD += 0.01
                print(f"Thumb touch threshold increased to {THUMB_TOUCH_THRESHOLD:.4f}")

            # ì›¹ì†Œì¼“ ì „ì†¡ (ì²« ë²ˆì§¸ ì¹´ë©”ë¼ ë°ì´í„° ì‚¬ìš©)
            if 0 in results_data and ws is not None:
                hand_data = results_data[0]
                current_time = time.time()

                if (hand_data["mode"] and hand_data["norm_dist"] > 0) or hand_data[
                    "mode"
                ] in ["mode0", "mode5"]:
                    camera_state = camera_states[0]

                    mode_changed = (
                        camera_state.last_confirmed_mode != camera_state.last_sent_mode
                        and camera_state.last_confirmed_mode is not None
                    )

                    if hand_data["mode"] in ["mode0", "mode5"] and mode_changed:
                        payload = {"m": 0 if hand_data["mode"] == "mode0" else 5}
                        try:
                            ws.send(json.dumps(payload))
                            camera_state.last_sent_mode = hand_data["mode"]
                            print(f"Mode change sent: {hand_data['mode']}")
                        except Exception as e:
                            print(f"WebSocket send error: {e}")
                            ws = None

                    elif (
                        hand_data["mode"] in ["mode1", "mode2"]
                        and current_time - camera_state.last_send_time >= 0.05
                    ):
                        # ê²€ì§€ ìƒíƒœ ë¶„ë¥˜
                        smoothed_index_angle = hand_data["smoothed_index_angle"]
                        if smoothed_index_angle <= 81:
                            index_status_code = 1
                        elif 82 <= smoothed_index_angle <= 114:
                            index_status_code = 2
                        else:
                            index_status_code = 3

                        if mode_changed or camera_state.last_sent_mode is None:
                            m_val = 1 if hand_data["mode"] == "mode1" else 2
                            payload = {"m": m_val, "is": index_status_code}
                            try:
                                ws.send(json.dumps(payload))
                                camera_state.last_sent_mode = hand_data["mode"]
                                camera_state.last_sent_is = index_status_code
                                print(
                                    f"Mode change sent: {hand_data['mode']} with is: {index_status_code}"
                                )
                            except Exception as e:
                                print(f"WebSocket send error: {e}")
                                ws = None
                        else:
                            if index_status_code != camera_state.last_sent_is:
                                payload = {"is": index_status_code}
                                try:
                                    ws.send(json.dumps(payload))
                                    camera_state.last_sent_is = index_status_code
                                    print(f"Data update sent: is={index_status_code}")
                                except Exception as e:
                                    print(f"WebSocket send error: {e}")
                                    ws = None

                        camera_state.last_send_time = current_time

    finally:
        # ì •ë¦¬
        hands_side.close()
        hands_bottom.close()
        cap0.release()
        cap1.release()
        cv2.destroyAllWindows()

        if ws:
            ws.close()

        # Unity ì›¹ì†Œì¼“ ì—°ê²° ì¢…ë£Œ
        if unity_websocket:
            unity_websocket.close()


def init_unity_websocket():
    """Unity ì›¹ì†Œì¼“ ì—°ê²°ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    global unity_websocket
    try:
        unity_websocket = websocket.WebSocket()
        unity_websocket.connect(UNITY_WEBSOCKET_URL)
        print(f"Unity ì›¹ì†Œì¼“ ì—°ê²° ì„±ê³µ: {UNITY_WEBSOCKET_URL}")
        return True
    except Exception as e:
        print(f"Unity ì›¹ì†Œì¼“ ì—°ê²° ì‹¤íŒ¨: {e}")
        unity_websocket = None
        return False


def send_gesture_to_unity(gesture_name):
    """ì œìŠ¤ì²˜ë¥¼ Unityë¡œ ìˆ«ìë¡œ ì „ì†¡í•©ë‹ˆë‹¤."""
    global unity_websocket, last_sent_gesture

    if not unity_websocket:
        return False

    # ë¬´ê¸° ì œìŠ¤ì²˜(Fire/Reload)ëŠ” í•­ìƒ ì „ì†¡ (ì¤‘ë³µ ë°©ì§€ ì•ˆí•¨)
    # ì¼ë°˜ ì œìŠ¤ì²˜(SG, S1 í¬í•¨)ëŠ” ì´ì „ê³¼ ë™ì¼í•œ ì œìŠ¤ì²˜ ì¬ì „ì†¡ ë°©ì§€
    if not is_weapon_gesture(gesture_name):
        if gesture_name == last_sent_gesture:
            return True

    try:
        gesture_number = GESTURE_TO_NUMBER.get(gesture_name, 0)

        if gesture_number == 0:
            print(f"ê²½ê³ : ì œìŠ¤ì²˜ '{gesture_name}'ì— ëŒ€í•œ ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ!")

        unity_websocket.send(str(gesture_number))

        # ì œìŠ¤ì²˜ ì „ì†¡ ë¡œê·¸
        if gesture_name == "SG":
            print(f"Unity ì „ì†¡: SG (ìƒ·ê±´ ë°œì‚¬) -> {gesture_number}")
        elif gesture_name == "S1":
            print(f"Unity ì „ì†¡: S1 (ìƒ·ê±´ ì¬ì¥ì „) -> {gesture_number}")
        elif "Fire" in gesture_name:
            print(f"Unity ì „ì†¡: {gesture_name} (ë°œì‚¬) -> {gesture_number}")
        elif "Reload" in gesture_name:
            print(f"Unity ì „ì†¡: {gesture_name} (ì¬ì¥ì „) -> {gesture_number}")
        else:
            print(f"Unity ì „ì†¡: {gesture_name} -> {gesture_number}")

        last_sent_gesture = gesture_name
        return True
    except Exception as e:
        print(f"Unity ì „ì†¡ ì‹¤íŒ¨: {e}")
        # ì—°ê²°ì´ ëŠì–´ì§„ ê²½ìš° ì¬ì—°ê²° ì‹œë„
        init_unity_websocket()
        return False


def send_no_gesture_to_unity():
    """ì œìŠ¤ì²˜ê°€ ì—†ìŒì„ Unityë¡œ ì „ì†¡í•©ë‹ˆë‹¤ (0)."""
    global unity_websocket, last_sent_gesture

    if not unity_websocket:
        return False

    # í˜„ì¬ ì „ì†¡ëœ ì œìŠ¤ì²˜ê°€ Fire/Reload ë¬´ê¸° ê´€ë ¨ì´ë©´ 0ì„ ë³´ë‚´ì§€ ì•ŠìŒ
    if is_weapon_gesture(last_sent_gesture):
        return True

    # ì´ë¯¸ 0ì„ ë³´ë‚¸ ìƒíƒœë©´ ì¬ì „ì†¡í•˜ì§€ ì•ŠìŒ
    if last_sent_gesture is None:
        return True

    try:
        unity_websocket.send("0")
        print("Unity ì „ì†¡: No Gesture -> 0")
        last_sent_gesture = None
        return True
    except Exception as e:
        print(f"Unity ì „ì†¡ ì‹¤íŒ¨: {e}")
        # ì—°ê²°ì´ ëŠì–´ì§„ ê²½ìš° ì¬ì—°ê²° ì‹œë„
        init_unity_websocket()
        return False


if __name__ == "__main__":
    main()
